//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-19805474
// Cuda compilation tools, release 7.5, V7.5.16
// Based on LLVM 3.4svn
//

.version 4.3
.target sm_20
.address_size 64

	// .globl	_Z8_Pow_intIdET_S0_i
.global .align 8 .b8 eye[12];
.global .align 4 .b8 U[12];
.global .align 4 .b8 V[12];
.global .align 4 .b8 W[12];
.global .align 4 .f32 fov;
.global .align 16 .b8 diffuse[16];
.global .align 4 .u32 texCount;
.global .align 16 .b8 lightDir[16];
.global .align 16 .b8 lightPos[16];
.global .align 8 .b8 top_object[4];
.global .align 1 .b8 vertex_buffer[1];
.global .align 1 .b8 index_buffer[1];
.global .align 1 .b8 normal[1];
.global .align 1 .b8 texCoord0[1];
.global .texref tex0;
.global .align 1 .b8 output0[1];
.global .align 4 .b8 ray[36];
.global .align 8 .b8 launch_index[8];
.global .align 8 .b8 launch_dim[8];
.global .align 16 .b8 prdr[32];
.global .align 16 .b8 prd_shadow[32];
.global .align 4 .f32 t_hit;
.global .align 8 .b8 texCoord[12];
.global .align 8 .b8 geometric_normal[12];
.global .align 8 .b8 shading_normal[12];
.global .align 4 .u32 Phong;
.global .align 4 .u32 Shadow;
.global .align 8 .u64 _ZN21rti_internal_register20reg_bitness_detectorE;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail0E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail1E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail2E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail3E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail4E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail5E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail6E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail7E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail8E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail9E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail0E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail1E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail2E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail3E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail4E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail5E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail6E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail7E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail8E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail9E;
.global .align 4 .u32 _ZN21rti_internal_register14reg_rayIndex_xE;
.global .align 4 .u32 _ZN21rti_internal_register14reg_rayIndex_yE;
.global .align 4 .u32 _ZN21rti_internal_register14reg_rayIndex_zE;
.global .align 4 .b8 _ZN21rti_internal_typeinfo3eyeE[8] = {82, 97, 121, 0, 12, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo1UE[8] = {82, 97, 121, 0, 12, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo1VE[8] = {82, 97, 121, 0, 12, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo1WE[8] = {82, 97, 121, 0, 12, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo3fovE[8] = {82, 97, 121, 0, 4, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo7diffuseE[8] = {82, 97, 121, 0, 16, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo8texCountE[8] = {82, 97, 121, 0, 4, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo8lightDirE[8] = {82, 97, 121, 0, 16, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo8lightPosE[8] = {82, 97, 121, 0, 16, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo10top_objectE[8] = {82, 97, 121, 0, 4, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo3rayE[8] = {82, 97, 121, 0, 36, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo12launch_indexE[8] = {82, 97, 121, 0, 8, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo10launch_dimE[8] = {82, 97, 121, 0, 8, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo4prdrE[8] = {82, 97, 121, 0, 32, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo10prd_shadowE[8] = {82, 97, 121, 0, 32, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo5t_hitE[8] = {82, 97, 121, 0, 4, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo8texCoordE[8] = {82, 97, 121, 0, 12, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo16geometric_normalE[8] = {82, 97, 121, 0, 12, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo14shading_normalE[8] = {82, 97, 121, 0, 12, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo5PhongE[8] = {82, 97, 121, 0, 4, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo6ShadowE[8] = {82, 97, 121, 0, 4, 0, 0, 0};
.global .align 1 .b8 _ZN21rti_internal_typename3eyeE[7] = {102, 108, 111, 97, 116, 51, 0};
.global .align 1 .b8 _ZN21rti_internal_typename1UE[7] = {102, 108, 111, 97, 116, 51, 0};
.global .align 1 .b8 _ZN21rti_internal_typename1VE[7] = {102, 108, 111, 97, 116, 51, 0};
.global .align 1 .b8 _ZN21rti_internal_typename1WE[7] = {102, 108, 111, 97, 116, 51, 0};
.global .align 1 .b8 _ZN21rti_internal_typename3fovE[6] = {102, 108, 111, 97, 116, 0};
.global .align 1 .b8 _ZN21rti_internal_typename7diffuseE[7] = {102, 108, 111, 97, 116, 52, 0};
.global .align 1 .b8 _ZN21rti_internal_typename8texCountE[4] = {105, 110, 116, 0};
.global .align 1 .b8 _ZN21rti_internal_typename8lightDirE[7] = {102, 108, 111, 97, 116, 52, 0};
.global .align 1 .b8 _ZN21rti_internal_typename8lightPosE[7] = {102, 108, 111, 97, 116, 52, 0};
.global .align 1 .b8 _ZN21rti_internal_typename10top_objectE[9] = {114, 116, 79, 98, 106, 101, 99, 116, 0};
.global .align 1 .b8 _ZN21rti_internal_typename3rayE[11] = {111, 112, 116, 105, 120, 58, 58, 82, 97, 121, 0};
.global .align 1 .b8 _ZN21rti_internal_typename12launch_indexE[6] = {117, 105, 110, 116, 50, 0};
.global .align 1 .b8 _ZN21rti_internal_typename10launch_dimE[6] = {117, 105, 110, 116, 50, 0};
.global .align 1 .b8 _ZN21rti_internal_typename4prdrE[17] = {80, 101, 114, 82, 97, 121, 68, 97, 116, 97, 82, 101, 115, 117, 108, 116, 0};
.global .align 1 .b8 _ZN21rti_internal_typename10prd_shadowE[18] = {80, 101, 114, 82, 97, 121, 68, 97, 116, 97, 95, 115, 104, 97, 100, 111, 119, 0};
.global .align 1 .b8 _ZN21rti_internal_typename5t_hitE[6] = {102, 108, 111, 97, 116, 0};
.global .align 1 .b8 _ZN21rti_internal_typename8texCoordE[7] = {102, 108, 111, 97, 116, 51, 0};
.global .align 1 .b8 _ZN21rti_internal_typename16geometric_normalE[7] = {102, 108, 111, 97, 116, 51, 0};
.global .align 1 .b8 _ZN21rti_internal_typename14shading_normalE[7] = {102, 108, 111, 97, 116, 51, 0};
.global .align 1 .b8 _ZN21rti_internal_typename5PhongE[4] = {105, 110, 116, 0};
.global .align 1 .b8 _ZN21rti_internal_typename6ShadowE[4] = {105, 110, 116, 0};
.global .align 4 .u32 _ZN21rti_internal_typeenum3eyeE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum1UE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum1VE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum1WE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum3fovE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum7diffuseE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum8texCountE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum8lightDirE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum8lightPosE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum10top_objectE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum3rayE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum12launch_indexE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum10launch_dimE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum4prdrE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum10prd_shadowE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum5t_hitE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum8texCoordE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum16geometric_normalE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum14shading_normalE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum5PhongE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum6ShadowE = 4919;
.global .align 1 .b8 _ZN21rti_internal_semantic3eyeE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic1UE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic1VE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic1WE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic3fovE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic7diffuseE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic8texCountE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic8lightDirE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic8lightPosE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic10top_objectE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic3rayE[13] = {114, 116, 67, 117, 114, 114, 101, 110, 116, 82, 97, 121, 0};
.global .align 1 .b8 _ZN21rti_internal_semantic12launch_indexE[14] = {114, 116, 76, 97, 117, 110, 99, 104, 73, 110, 100, 101, 120, 0};
.global .align 1 .b8 _ZN21rti_internal_semantic10launch_dimE[12] = {114, 116, 76, 97, 117, 110, 99, 104, 68, 105, 109, 0};
.global .align 1 .b8 _ZN21rti_internal_semantic4prdrE[10] = {114, 116, 80, 97, 121, 108, 111, 97, 100, 0};
.global .align 1 .b8 _ZN21rti_internal_semantic10prd_shadowE[10] = {114, 116, 80, 97, 121, 108, 111, 97, 100, 0};
.global .align 1 .b8 _ZN21rti_internal_semantic5t_hitE[23] = {114, 116, 73, 110, 116, 101, 114, 115, 101, 99, 116, 105, 111, 110, 68, 105, 115, 116, 97, 110, 99, 101, 0};
.global .align 1 .b8 _ZN21rti_internal_semantic8texCoordE[19] = {97, 116, 116, 114, 105, 98, 117, 116, 101, 32, 116, 101, 120, 99, 111, 111, 114, 100, 0};
.global .align 1 .b8 _ZN21rti_internal_semantic16geometric_normalE[27] = {97, 116, 116, 114, 105, 98, 117, 116, 101, 32, 103, 101, 111, 109, 101, 116, 114, 105, 99, 95, 110, 111, 114, 109, 97, 108, 0};
.global .align 1 .b8 _ZN21rti_internal_semantic14shading_normalE[25] = {97, 116, 116, 114, 105, 98, 117, 116, 101, 32, 115, 104, 97, 100, 105, 110, 103, 95, 110, 111, 114, 109, 97, 108, 0};
.global .align 1 .b8 _ZN21rti_internal_semantic5PhongE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic6ShadowE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation3eyeE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation1UE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation1VE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation1WE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation3fovE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation7diffuseE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation8texCountE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation8lightDirE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation8lightPosE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation10top_objectE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation3rayE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation12launch_indexE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation10launch_dimE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation4prdrE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation10prd_shadowE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation5t_hitE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation8texCoordE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation16geometric_normalE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation14shading_normalE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation5PhongE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation6ShadowE[1];

.visible .func  (.param .b64 func_retval0) _Z8_Pow_intIdET_S0_i(
	.param .b64 _Z8_Pow_intIdET_S0_i_param_0,
	.param .b32 _Z8_Pow_intIdET_S0_i_param_1
)
{
	.reg .pred 	%p<10>;
	.reg .b32 	%r<12>;
	.reg .f64 	%fd<13>;


	ld.param.f64 	%fd11, [_Z8_Pow_intIdET_S0_i_param_0];
	ld.param.u32 	%r4, [_Z8_Pow_intIdET_S0_i_param_1];
	shr.s32 	%r5, %r4, 31;
	add.s32 	%r6, %r4, %r5;
	xor.b32  	%r7, %r6, %r5;
	and.b32  	%r8, %r6, 1;
	setp.eq.b32	%p1, %r8, 1;
	and.b32  	%r9, %r5, 1;
	setp.eq.b32	%p2, %r9, 1;
	xor.pred  	%p3, %p1, %p2;
	not.pred 	%p4, %p3;
	selp.f64	%fd12, 0d3FF0000000000000, %fd11, %p4;
	shr.u32 	%r11, %r7, 1;
	setp.eq.s32	%p5, %r11, 0;
	@%p5 bra 	BB0_2;

BB0_1:
	and.b32  	%r10, %r11, 1;
	setp.eq.b32	%p6, %r10, 1;
	not.pred 	%p7, %p6;
	mul.f64 	%fd11, %fd11, %fd11;
	mul.f64 	%fd10, %fd12, %fd11;
	selp.f64	%fd12, %fd12, %fd10, %p7;
	shr.u32 	%r11, %r11, 1;
	setp.ne.s32	%p8, %r11, 0;
	@%p8 bra 	BB0_1;

BB0_2:
	setp.gt.s32	%p9, %r4, -1;
	@%p9 bra 	BB0_4;

	rcp.rn.f64 	%fd12, %fd12;

BB0_4:
	st.param.f64	[func_retval0+0], %fd12;
	ret;
}

	// .globl	_Z3teaILj16EEjjj
.visible .func  (.param .b32 func_retval0) _Z3teaILj16EEjjj(
	.param .b32 _Z3teaILj16EEjjj_param_0,
	.param .b32 _Z3teaILj16EEjjj_param_1
)
{
	.reg .b32 	%r<251>;


	ld.param.u32 	%r1, [_Z3teaILj16EEjjj_param_0];
	ld.param.u32 	%r2, [_Z3teaILj16EEjjj_param_1];
	shl.b32 	%r3, %r2, 4;
	add.s32 	%r4, %r3, -1556008596;
	add.s32 	%r5, %r2, -1640531527;
	xor.b32  	%r6, %r4, %r5;
	shr.u32 	%r7, %r2, 5;
	add.s32 	%r8, %r7, -939442524;
	xor.b32  	%r9, %r6, %r8;
	add.s32 	%r10, %r9, %r1;
	shl.b32 	%r11, %r10, 4;
	add.s32 	%r12, %r11, -1383041155;
	add.s32 	%r13, %r10, -1640531527;
	xor.b32  	%r14, %r12, %r13;
	shr.u32 	%r15, %r10, 5;
	add.s32 	%r16, %r15, 2123724318;
	xor.b32  	%r17, %r14, %r16;
	add.s32 	%r18, %r17, %r2;
	shl.b32 	%r19, %r18, 4;
	add.s32 	%r20, %r19, -1556008596;
	add.s32 	%r21, %r18, 1013904242;
	xor.b32  	%r22, %r20, %r21;
	shr.u32 	%r23, %r18, 5;
	add.s32 	%r24, %r23, -939442524;
	xor.b32  	%r25, %r22, %r24;
	add.s32 	%r26, %r25, %r10;
	shl.b32 	%r27, %r26, 4;
	add.s32 	%r28, %r27, -1383041155;
	add.s32 	%r29, %r26, 1013904242;
	xor.b32  	%r30, %r28, %r29;
	shr.u32 	%r31, %r26, 5;
	add.s32 	%r32, %r31, 2123724318;
	xor.b32  	%r33, %r30, %r32;
	add.s32 	%r34, %r33, %r18;
	shl.b32 	%r35, %r34, 4;
	add.s32 	%r36, %r35, -1556008596;
	add.s32 	%r37, %r34, -626627285;
	xor.b32  	%r38, %r36, %r37;
	shr.u32 	%r39, %r34, 5;
	add.s32 	%r40, %r39, -939442524;
	xor.b32  	%r41, %r38, %r40;
	add.s32 	%r42, %r41, %r26;
	shl.b32 	%r43, %r42, 4;
	add.s32 	%r44, %r43, -1383041155;
	add.s32 	%r45, %r42, -626627285;
	xor.b32  	%r46, %r44, %r45;
	shr.u32 	%r47, %r42, 5;
	add.s32 	%r48, %r47, 2123724318;
	xor.b32  	%r49, %r46, %r48;
	add.s32 	%r50, %r49, %r34;
	shl.b32 	%r51, %r50, 4;
	add.s32 	%r52, %r51, -1556008596;
	add.s32 	%r53, %r50, 2027808484;
	xor.b32  	%r54, %r52, %r53;
	shr.u32 	%r55, %r50, 5;
	add.s32 	%r56, %r55, -939442524;
	xor.b32  	%r57, %r54, %r56;
	add.s32 	%r58, %r57, %r42;
	shl.b32 	%r59, %r58, 4;
	add.s32 	%r60, %r59, -1383041155;
	add.s32 	%r61, %r58, 2027808484;
	xor.b32  	%r62, %r60, %r61;
	shr.u32 	%r63, %r58, 5;
	add.s32 	%r64, %r63, 2123724318;
	xor.b32  	%r65, %r62, %r64;
	add.s32 	%r66, %r65, %r50;
	shl.b32 	%r67, %r66, 4;
	add.s32 	%r68, %r67, -1556008596;
	add.s32 	%r69, %r66, 387276957;
	xor.b32  	%r70, %r68, %r69;
	shr.u32 	%r71, %r66, 5;
	add.s32 	%r72, %r71, -939442524;
	xor.b32  	%r73, %r70, %r72;
	add.s32 	%r74, %r73, %r58;
	shl.b32 	%r75, %r74, 4;
	add.s32 	%r76, %r75, -1383041155;
	add.s32 	%r77, %r74, 387276957;
	xor.b32  	%r78, %r76, %r77;
	shr.u32 	%r79, %r74, 5;
	add.s32 	%r80, %r79, 2123724318;
	xor.b32  	%r81, %r78, %r80;
	add.s32 	%r82, %r81, %r66;
	shl.b32 	%r83, %r82, 4;
	add.s32 	%r84, %r83, -1556008596;
	add.s32 	%r85, %r82, -1253254570;
	xor.b32  	%r86, %r84, %r85;
	shr.u32 	%r87, %r82, 5;
	add.s32 	%r88, %r87, -939442524;
	xor.b32  	%r89, %r86, %r88;
	add.s32 	%r90, %r89, %r74;
	shl.b32 	%r91, %r90, 4;
	add.s32 	%r92, %r91, -1383041155;
	add.s32 	%r93, %r90, -1253254570;
	xor.b32  	%r94, %r92, %r93;
	shr.u32 	%r95, %r90, 5;
	add.s32 	%r96, %r95, 2123724318;
	xor.b32  	%r97, %r94, %r96;
	add.s32 	%r98, %r97, %r82;
	shl.b32 	%r99, %r98, 4;
	add.s32 	%r100, %r99, -1556008596;
	add.s32 	%r101, %r98, 1401181199;
	xor.b32  	%r102, %r100, %r101;
	shr.u32 	%r103, %r98, 5;
	add.s32 	%r104, %r103, -939442524;
	xor.b32  	%r105, %r102, %r104;
	add.s32 	%r106, %r105, %r90;
	shl.b32 	%r107, %r106, 4;
	add.s32 	%r108, %r107, -1383041155;
	add.s32 	%r109, %r106, 1401181199;
	xor.b32  	%r110, %r108, %r109;
	shr.u32 	%r111, %r106, 5;
	add.s32 	%r112, %r111, 2123724318;
	xor.b32  	%r113, %r110, %r112;
	add.s32 	%r114, %r113, %r98;
	shl.b32 	%r115, %r114, 4;
	add.s32 	%r116, %r115, -1556008596;
	add.s32 	%r117, %r114, -239350328;
	xor.b32  	%r118, %r116, %r117;
	shr.u32 	%r119, %r114, 5;
	add.s32 	%r120, %r119, -939442524;
	xor.b32  	%r121, %r118, %r120;
	add.s32 	%r122, %r121, %r106;
	shl.b32 	%r123, %r122, 4;
	add.s32 	%r124, %r123, -1383041155;
	add.s32 	%r125, %r122, -239350328;
	xor.b32  	%r126, %r124, %r125;
	shr.u32 	%r127, %r122, 5;
	add.s32 	%r128, %r127, 2123724318;
	xor.b32  	%r129, %r126, %r128;
	add.s32 	%r130, %r129, %r114;
	shl.b32 	%r131, %r130, 4;
	add.s32 	%r132, %r131, -1556008596;
	add.s32 	%r133, %r130, -1879881855;
	xor.b32  	%r134, %r132, %r133;
	shr.u32 	%r135, %r130, 5;
	add.s32 	%r136, %r135, -939442524;
	xor.b32  	%r137, %r134, %r136;
	add.s32 	%r138, %r137, %r122;
	shl.b32 	%r139, %r138, 4;
	add.s32 	%r140, %r139, -1383041155;
	add.s32 	%r141, %r138, -1879881855;
	xor.b32  	%r142, %r140, %r141;
	shr.u32 	%r143, %r138, 5;
	add.s32 	%r144, %r143, 2123724318;
	xor.b32  	%r145, %r142, %r144;
	add.s32 	%r146, %r145, %r130;
	shl.b32 	%r147, %r146, 4;
	add.s32 	%r148, %r147, -1556008596;
	add.s32 	%r149, %r146, 774553914;
	xor.b32  	%r150, %r148, %r149;
	shr.u32 	%r151, %r146, 5;
	add.s32 	%r152, %r151, -939442524;
	xor.b32  	%r153, %r150, %r152;
	add.s32 	%r154, %r153, %r138;
	shl.b32 	%r155, %r154, 4;
	add.s32 	%r156, %r155, -1383041155;
	add.s32 	%r157, %r154, 774553914;
	xor.b32  	%r158, %r156, %r157;
	shr.u32 	%r159, %r154, 5;
	add.s32 	%r160, %r159, 2123724318;
	xor.b32  	%r161, %r158, %r160;
	add.s32 	%r162, %r161, %r146;
	shl.b32 	%r163, %r162, 4;
	add.s32 	%r164, %r163, -1556008596;
	add.s32 	%r165, %r162, -865977613;
	xor.b32  	%r166, %r164, %r165;
	shr.u32 	%r167, %r162, 5;
	add.s32 	%r168, %r167, -939442524;
	xor.b32  	%r169, %r166, %r168;
	add.s32 	%r170, %r169, %r154;
	shl.b32 	%r171, %r170, 4;
	add.s32 	%r172, %r171, -1383041155;
	add.s32 	%r173, %r170, -865977613;
	xor.b32  	%r174, %r172, %r173;
	shr.u32 	%r175, %r170, 5;
	add.s32 	%r176, %r175, 2123724318;
	xor.b32  	%r177, %r174, %r176;
	add.s32 	%r178, %r177, %r162;
	shl.b32 	%r179, %r178, 4;
	add.s32 	%r180, %r179, -1556008596;
	add.s32 	%r181, %r178, 1788458156;
	xor.b32  	%r182, %r180, %r181;
	shr.u32 	%r183, %r178, 5;
	add.s32 	%r184, %r183, -939442524;
	xor.b32  	%r185, %r182, %r184;
	add.s32 	%r186, %r185, %r170;
	shl.b32 	%r187, %r186, 4;
	add.s32 	%r188, %r187, -1383041155;
	add.s32 	%r189, %r186, 1788458156;
	xor.b32  	%r190, %r188, %r189;
	shr.u32 	%r191, %r186, 5;
	add.s32 	%r192, %r191, 2123724318;
	xor.b32  	%r193, %r190, %r192;
	add.s32 	%r194, %r193, %r178;
	shl.b32 	%r195, %r194, 4;
	add.s32 	%r196, %r195, -1556008596;
	add.s32 	%r197, %r194, 147926629;
	xor.b32  	%r198, %r196, %r197;
	shr.u32 	%r199, %r194, 5;
	add.s32 	%r200, %r199, -939442524;
	xor.b32  	%r201, %r198, %r200;
	add.s32 	%r202, %r201, %r186;
	shl.b32 	%r203, %r202, 4;
	add.s32 	%r204, %r203, -1383041155;
	add.s32 	%r205, %r202, 147926629;
	xor.b32  	%r206, %r204, %r205;
	shr.u32 	%r207, %r202, 5;
	add.s32 	%r208, %r207, 2123724318;
	xor.b32  	%r209, %r206, %r208;
	add.s32 	%r210, %r209, %r194;
	shl.b32 	%r211, %r210, 4;
	add.s32 	%r212, %r211, -1556008596;
	add.s32 	%r213, %r210, -1492604898;
	xor.b32  	%r214, %r212, %r213;
	shr.u32 	%r215, %r210, 5;
	add.s32 	%r216, %r215, -939442524;
	xor.b32  	%r217, %r214, %r216;
	add.s32 	%r218, %r217, %r202;
	shl.b32 	%r219, %r218, 4;
	add.s32 	%r220, %r219, -1383041155;
	add.s32 	%r221, %r218, -1492604898;
	xor.b32  	%r222, %r220, %r221;
	shr.u32 	%r223, %r218, 5;
	add.s32 	%r224, %r223, 2123724318;
	xor.b32  	%r225, %r222, %r224;
	add.s32 	%r226, %r225, %r210;
	shl.b32 	%r227, %r226, 4;
	add.s32 	%r228, %r227, -1556008596;
	add.s32 	%r229, %r226, 1161830871;
	xor.b32  	%r230, %r228, %r229;
	shr.u32 	%r231, %r226, 5;
	add.s32 	%r232, %r231, -939442524;
	xor.b32  	%r233, %r230, %r232;
	add.s32 	%r234, %r233, %r218;
	shl.b32 	%r235, %r234, 4;
	add.s32 	%r236, %r235, -1383041155;
	add.s32 	%r237, %r234, 1161830871;
	xor.b32  	%r238, %r236, %r237;
	shr.u32 	%r239, %r234, 5;
	add.s32 	%r240, %r239, 2123724318;
	xor.b32  	%r241, %r238, %r240;
	add.s32 	%r242, %r241, %r226;
	shl.b32 	%r243, %r242, 4;
	add.s32 	%r244, %r243, -1556008596;
	add.s32 	%r245, %r242, -478700656;
	xor.b32  	%r246, %r244, %r245;
	shr.u32 	%r247, %r242, 5;
	add.s32 	%r248, %r247, -939442524;
	xor.b32  	%r249, %r246, %r248;
	add.s32 	%r250, %r249, %r234;
	st.param.b32	[func_retval0+0], %r250;
	ret;
}

	// .globl	_Z14pinhole_camerav
.visible .entry _Z14pinhole_camerav(

)
{
	.local .align 16 .b8 	__local_depot2[32];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .f32 	%f<58>;
	.reg .b32 	%r<15>;
	.reg .b64 	%rd<20>;


	mov.u64 	%rd19, __local_depot2;
	cvta.local.u64 	%SP, %rd19;
	add.u64 	%rd1, %SP, 0;
	cvta.to.local.u64 	%rd8, %rd1;
	ldu.global.v2.u32 	{%r6, %r7}, [launch_index];
	cvt.rn.f32.u32	%f9, %r6;
	cvt.rn.f32.u32	%f10, %r7;
	ldu.global.v2.u32 	{%r10, %r11}, [launch_dim];
	cvt.rn.f32.u32	%f11, %r10;
	cvt.rn.f32.u32	%f12, %r11;
	div.approx.ftz.f32 	%f13, %f9, %f11;
	div.approx.ftz.f32 	%f14, %f10, %f12;
	fma.rn.ftz.f32 	%f15, %f13, 0f40000000, 0fBF800000;
	fma.rn.ftz.f32 	%f16, %f14, 0f40000000, 0fBF800000;
	ld.global.v2.f32 	{%f17, %f18}, [eye];
	ld.global.f32 	%f3, [eye+8];
	mov.u64 	%rd9, U;
	ldu.global.f32 	%f19, [U];
	mul.ftz.f32 	%f20, %f15, %f19;
	add.s64 	%rd10, %rd9, 4;
	ldu.global.f32 	%f21, [%rd10];
	mul.ftz.f32 	%f22, %f15, %f21;
	add.s64 	%rd11, %rd9, 8;
	ldu.global.f32 	%f23, [%rd11];
	mul.ftz.f32 	%f24, %f15, %f23;
	ldu.global.f32 	%f25, [fov];
	mov.u64 	%rd12, V;
	ldu.global.f32 	%f26, [V];
	mul.ftz.f32 	%f27, %f16, %f26;
	add.s64 	%rd13, %rd12, 4;
	ldu.global.f32 	%f28, [%rd13];
	mul.ftz.f32 	%f29, %f16, %f28;
	add.s64 	%rd14, %rd12, 8;
	ldu.global.f32 	%f30, [%rd14];
	mul.ftz.f32 	%f31, %f16, %f30;
	mul.ftz.f32 	%f32, %f27, %f25;
	mul.ftz.f32 	%f33, %f29, %f25;
	mul.ftz.f32 	%f34, %f31, %f25;
	fma.rn.ftz.f32 	%f35, %f20, %f25, %f32;
	fma.rn.ftz.f32 	%f36, %f22, %f25, %f33;
	fma.rn.ftz.f32 	%f37, %f24, %f25, %f34;
	mov.u64 	%rd15, W;
	ldu.global.f32 	%f38, [W];
	add.ftz.f32 	%f39, %f38, %f35;
	add.s64 	%rd16, %rd15, 4;
	ldu.global.f32 	%f40, [%rd16];
	add.ftz.f32 	%f41, %f36, %f40;
	add.s64 	%rd17, %rd15, 8;
	ldu.global.f32 	%f42, [%rd17];
	add.ftz.f32 	%f43, %f37, %f42;
	mul.ftz.f32 	%f44, %f41, %f41;
	fma.rn.ftz.f32 	%f45, %f39, %f39, %f44;
	fma.rn.ftz.f32 	%f46, %f43, %f43, %f45;
	sqrt.approx.ftz.f32 	%f47, %f46;
	rcp.approx.ftz.f32 	%f48, %f47;
	mul.ftz.f32 	%f4, %f39, %f48;
	mul.ftz.f32 	%f5, %f41, %f48;
	mul.ftz.f32 	%f6, %f43, %f48;
	ldu.global.u32 	%r2, [Phong];
	mov.f32 	%f49, 0f3F800000;
	st.local.v4.f32 	[%rd8], {%f49, %f49, %f49, %f49};
	mov.u32 	%r14, 0;
	st.local.u32 	[%rd8+16], %r14;
	ldu.global.u32 	%r1, [top_object];
	mov.f32 	%f7, 0f2D2FEBFF;
	mov.f32 	%f8, 0f6C4ECB8F;
	mov.u32 	%r3, 32;
	// inline asm
	call _rt_trace_64, (%r1, %f17, %f18, %f3, %f4, %f5, %f6, %r2, %f7, %f8, %rd1, %r3);
	// inline asm
	ld.global.u32 	%rd4, [launch_index];
	ld.global.u32 	%rd5, [launch_index+4];
	mov.u64 	%rd18, output0;
	cvta.global.u64 	%rd3, %rd18;
	mov.u32 	%r4, 2;
	mov.u32 	%r5, 16;
	mov.u64 	%rd7, 0;
	// inline asm
	call (%rd2), _rt_buffer_get_64, (%rd3, %r4, %r5, %rd4, %rd5, %rd7, %rd7);
	// inline asm
	ld.local.v4.f32 	{%f50, %f51, %f52, %f53}, [%rd8];
	st.v4.f32 	[%rd2], {%f50, %f51, %f52, %f53};
	ret;
}

	// .globl	_Z17pinhole_camera_msv
.visible .entry _Z17pinhole_camera_msv(

)
{
	.local .align 16 .b8 	__local_depot3[32];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .f32 	%f<73>;
	.reg .b32 	%r<501>;
	.reg .b64 	%rd<20>;


	mov.u64 	%rd19, __local_depot3;
	cvta.local.u64 	%SP, %rd19;
	add.u64 	%rd1, %SP, 0;
	cvta.to.local.u64 	%rd8, %rd1;
	ldu.global.v2.u32 	{%r6, %r7}, [launch_index];
	cvt.rn.f32.u32	%f9, %r6;
	cvt.rn.f32.u32	%f10, %r7;
	ldu.global.v2.u32 	{%r10, %r11}, [launch_dim];
	cvt.rn.f32.u32	%f11, %r10;
	cvt.rn.f32.u32	%f12, %r11;
	div.approx.ftz.f32 	%f13, %f9, %f11;
	div.approx.ftz.f32 	%f14, %f10, %f12;
	fma.rn.ftz.f32 	%f15, %f13, 0f40000000, 0fBF800000;
	fma.rn.ftz.f32 	%f16, %f14, 0f40000000, 0fBF800000;
	rcp.approx.ftz.f32 	%f17, %f11;
	rcp.approx.ftz.f32 	%f18, %f12;
	add.ftz.f32 	%f19, %f17, %f17;
	add.ftz.f32 	%f20, %f18, %f18;
	mad.lo.s32 	%r14, %r7, %r10, %r6;
	add.s32 	%r15, %r14, -176720271;
	shl.b32 	%r16, %r15, 4;
	add.s32 	%r17, %r16, -1383041155;
	add.s32 	%r18, %r14, -1817251798;
	xor.b32  	%r19, %r17, %r18;
	shr.u32 	%r20, %r15, 5;
	add.s32 	%r21, %r20, 2123724318;
	xor.b32  	%r22, %r19, %r21;
	shl.b32 	%r23, %r22, 4;
	add.s32 	%r24, %r23, -1556008596;
	add.s32 	%r25, %r22, 1013904242;
	xor.b32  	%r26, %r24, %r25;
	shr.u32 	%r27, %r22, 5;
	add.s32 	%r28, %r27, -939442524;
	xor.b32  	%r29, %r26, %r28;
	add.s32 	%r30, %r29, %r15;
	shl.b32 	%r31, %r30, 4;
	add.s32 	%r32, %r31, -1383041155;
	add.s32 	%r33, %r30, 1013904242;
	xor.b32  	%r34, %r32, %r33;
	shr.u32 	%r35, %r30, 5;
	add.s32 	%r36, %r35, 2123724318;
	xor.b32  	%r37, %r34, %r36;
	add.s32 	%r38, %r37, %r22;
	shl.b32 	%r39, %r38, 4;
	add.s32 	%r40, %r39, -1556008596;
	add.s32 	%r41, %r38, -626627285;
	xor.b32  	%r42, %r40, %r41;
	shr.u32 	%r43, %r38, 5;
	add.s32 	%r44, %r43, -939442524;
	xor.b32  	%r45, %r42, %r44;
	add.s32 	%r46, %r45, %r30;
	shl.b32 	%r47, %r46, 4;
	add.s32 	%r48, %r47, -1383041155;
	add.s32 	%r49, %r46, -626627285;
	xor.b32  	%r50, %r48, %r49;
	shr.u32 	%r51, %r46, 5;
	add.s32 	%r52, %r51, 2123724318;
	xor.b32  	%r53, %r50, %r52;
	add.s32 	%r54, %r53, %r38;
	shl.b32 	%r55, %r54, 4;
	add.s32 	%r56, %r55, -1556008596;
	add.s32 	%r57, %r54, 2027808484;
	xor.b32  	%r58, %r56, %r57;
	shr.u32 	%r59, %r54, 5;
	add.s32 	%r60, %r59, -939442524;
	xor.b32  	%r61, %r58, %r60;
	add.s32 	%r62, %r61, %r46;
	shl.b32 	%r63, %r62, 4;
	add.s32 	%r64, %r63, -1383041155;
	add.s32 	%r65, %r62, 2027808484;
	xor.b32  	%r66, %r64, %r65;
	shr.u32 	%r67, %r62, 5;
	add.s32 	%r68, %r67, 2123724318;
	xor.b32  	%r69, %r66, %r68;
	add.s32 	%r70, %r69, %r54;
	shl.b32 	%r71, %r70, 4;
	add.s32 	%r72, %r71, -1556008596;
	add.s32 	%r73, %r70, 387276957;
	xor.b32  	%r74, %r72, %r73;
	shr.u32 	%r75, %r70, 5;
	add.s32 	%r76, %r75, -939442524;
	xor.b32  	%r77, %r74, %r76;
	add.s32 	%r78, %r77, %r62;
	shl.b32 	%r79, %r78, 4;
	add.s32 	%r80, %r79, -1383041155;
	add.s32 	%r81, %r78, 387276957;
	xor.b32  	%r82, %r80, %r81;
	shr.u32 	%r83, %r78, 5;
	add.s32 	%r84, %r83, 2123724318;
	xor.b32  	%r85, %r82, %r84;
	add.s32 	%r86, %r85, %r70;
	shl.b32 	%r87, %r86, 4;
	add.s32 	%r88, %r87, -1556008596;
	add.s32 	%r89, %r86, -1253254570;
	xor.b32  	%r90, %r88, %r89;
	shr.u32 	%r91, %r86, 5;
	add.s32 	%r92, %r91, -939442524;
	xor.b32  	%r93, %r90, %r92;
	add.s32 	%r94, %r93, %r78;
	shl.b32 	%r95, %r94, 4;
	add.s32 	%r96, %r95, -1383041155;
	add.s32 	%r97, %r94, -1253254570;
	xor.b32  	%r98, %r96, %r97;
	shr.u32 	%r99, %r94, 5;
	add.s32 	%r100, %r99, 2123724318;
	xor.b32  	%r101, %r98, %r100;
	add.s32 	%r102, %r101, %r86;
	shl.b32 	%r103, %r102, 4;
	add.s32 	%r104, %r103, -1556008596;
	add.s32 	%r105, %r102, 1401181199;
	xor.b32  	%r106, %r104, %r105;
	shr.u32 	%r107, %r102, 5;
	add.s32 	%r108, %r107, -939442524;
	xor.b32  	%r109, %r106, %r108;
	add.s32 	%r110, %r109, %r94;
	shl.b32 	%r111, %r110, 4;
	add.s32 	%r112, %r111, -1383041155;
	add.s32 	%r113, %r110, 1401181199;
	xor.b32  	%r114, %r112, %r113;
	shr.u32 	%r115, %r110, 5;
	add.s32 	%r116, %r115, 2123724318;
	xor.b32  	%r117, %r114, %r116;
	add.s32 	%r118, %r117, %r102;
	shl.b32 	%r119, %r118, 4;
	add.s32 	%r120, %r119, -1556008596;
	add.s32 	%r121, %r118, -239350328;
	xor.b32  	%r122, %r120, %r121;
	shr.u32 	%r123, %r118, 5;
	add.s32 	%r124, %r123, -939442524;
	xor.b32  	%r125, %r122, %r124;
	add.s32 	%r126, %r125, %r110;
	shl.b32 	%r127, %r126, 4;
	add.s32 	%r128, %r127, -1383041155;
	add.s32 	%r129, %r126, -239350328;
	xor.b32  	%r130, %r128, %r129;
	shr.u32 	%r131, %r126, 5;
	add.s32 	%r132, %r131, 2123724318;
	xor.b32  	%r133, %r130, %r132;
	add.s32 	%r134, %r133, %r118;
	shl.b32 	%r135, %r134, 4;
	add.s32 	%r136, %r135, -1556008596;
	add.s32 	%r137, %r134, -1879881855;
	xor.b32  	%r138, %r136, %r137;
	shr.u32 	%r139, %r134, 5;
	add.s32 	%r140, %r139, -939442524;
	xor.b32  	%r141, %r138, %r140;
	add.s32 	%r142, %r141, %r126;
	shl.b32 	%r143, %r142, 4;
	add.s32 	%r144, %r143, -1383041155;
	add.s32 	%r145, %r142, -1879881855;
	xor.b32  	%r146, %r144, %r145;
	shr.u32 	%r147, %r142, 5;
	add.s32 	%r148, %r147, 2123724318;
	xor.b32  	%r149, %r146, %r148;
	add.s32 	%r150, %r149, %r134;
	shl.b32 	%r151, %r150, 4;
	add.s32 	%r152, %r151, -1556008596;
	add.s32 	%r153, %r150, 774553914;
	xor.b32  	%r154, %r152, %r153;
	shr.u32 	%r155, %r150, 5;
	add.s32 	%r156, %r155, -939442524;
	xor.b32  	%r157, %r154, %r156;
	add.s32 	%r158, %r157, %r142;
	shl.b32 	%r159, %r158, 4;
	add.s32 	%r160, %r159, -1383041155;
	add.s32 	%r161, %r158, 774553914;
	xor.b32  	%r162, %r160, %r161;
	shr.u32 	%r163, %r158, 5;
	add.s32 	%r164, %r163, 2123724318;
	xor.b32  	%r165, %r162, %r164;
	add.s32 	%r166, %r165, %r150;
	shl.b32 	%r167, %r166, 4;
	add.s32 	%r168, %r167, -1556008596;
	add.s32 	%r169, %r166, -865977613;
	xor.b32  	%r170, %r168, %r169;
	shr.u32 	%r171, %r166, 5;
	add.s32 	%r172, %r171, -939442524;
	xor.b32  	%r173, %r170, %r172;
	add.s32 	%r174, %r173, %r158;
	shl.b32 	%r175, %r174, 4;
	add.s32 	%r176, %r175, -1383041155;
	add.s32 	%r177, %r174, -865977613;
	xor.b32  	%r178, %r176, %r177;
	shr.u32 	%r179, %r174, 5;
	add.s32 	%r180, %r179, 2123724318;
	xor.b32  	%r181, %r178, %r180;
	add.s32 	%r182, %r181, %r166;
	shl.b32 	%r183, %r182, 4;
	add.s32 	%r184, %r183, -1556008596;
	add.s32 	%r185, %r182, 1788458156;
	xor.b32  	%r186, %r184, %r185;
	shr.u32 	%r187, %r182, 5;
	add.s32 	%r188, %r187, -939442524;
	xor.b32  	%r189, %r186, %r188;
	add.s32 	%r190, %r189, %r174;
	shl.b32 	%r191, %r190, 4;
	add.s32 	%r192, %r191, -1383041155;
	add.s32 	%r193, %r190, 1788458156;
	xor.b32  	%r194, %r192, %r193;
	shr.u32 	%r195, %r190, 5;
	add.s32 	%r196, %r195, 2123724318;
	xor.b32  	%r197, %r194, %r196;
	add.s32 	%r198, %r197, %r182;
	shl.b32 	%r199, %r198, 4;
	add.s32 	%r200, %r199, -1556008596;
	add.s32 	%r201, %r198, 147926629;
	xor.b32  	%r202, %r200, %r201;
	shr.u32 	%r203, %r198, 5;
	add.s32 	%r204, %r203, -939442524;
	xor.b32  	%r205, %r202, %r204;
	add.s32 	%r206, %r205, %r190;
	shl.b32 	%r207, %r206, 4;
	add.s32 	%r208, %r207, -1383041155;
	add.s32 	%r209, %r206, 147926629;
	xor.b32  	%r210, %r208, %r209;
	shr.u32 	%r211, %r206, 5;
	add.s32 	%r212, %r211, 2123724318;
	xor.b32  	%r213, %r210, %r212;
	add.s32 	%r214, %r213, %r198;
	shl.b32 	%r215, %r214, 4;
	add.s32 	%r216, %r215, -1556008596;
	add.s32 	%r217, %r214, -1492604898;
	xor.b32  	%r218, %r216, %r217;
	shr.u32 	%r219, %r214, 5;
	add.s32 	%r220, %r219, -939442524;
	xor.b32  	%r221, %r218, %r220;
	add.s32 	%r222, %r221, %r206;
	shl.b32 	%r223, %r222, 4;
	add.s32 	%r224, %r223, -1383041155;
	add.s32 	%r225, %r222, -1492604898;
	xor.b32  	%r226, %r224, %r225;
	shr.u32 	%r227, %r222, 5;
	add.s32 	%r228, %r227, 2123724318;
	xor.b32  	%r229, %r226, %r228;
	add.s32 	%r230, %r229, %r214;
	shl.b32 	%r231, %r230, 4;
	add.s32 	%r232, %r231, -1556008596;
	add.s32 	%r233, %r230, 1161830871;
	xor.b32  	%r234, %r232, %r233;
	shr.u32 	%r235, %r230, 5;
	add.s32 	%r236, %r235, -939442524;
	xor.b32  	%r237, %r234, %r236;
	add.s32 	%r238, %r237, %r222;
	shl.b32 	%r239, %r238, 4;
	add.s32 	%r240, %r239, -1383041155;
	add.s32 	%r241, %r238, 1161830871;
	xor.b32  	%r242, %r240, %r241;
	shr.u32 	%r243, %r238, 5;
	add.s32 	%r244, %r243, 2123724318;
	xor.b32  	%r245, %r242, %r244;
	add.s32 	%r246, %r245, %r230;
	shl.b32 	%r247, %r246, 4;
	add.s32 	%r248, %r247, -1556008596;
	add.s32 	%r249, %r246, -478700656;
	xor.b32  	%r250, %r248, %r249;
	shr.u32 	%r251, %r246, 5;
	add.s32 	%r252, %r251, -939442524;
	xor.b32  	%r253, %r250, %r252;
	add.s32 	%r254, %r253, %r238;
	add.s32 	%r255, %r14, -176720286;
	shl.b32 	%r256, %r255, 4;
	add.s32 	%r257, %r256, -1383041155;
	add.s32 	%r258, %r14, -1817251813;
	xor.b32  	%r259, %r257, %r258;
	shr.u32 	%r260, %r255, 5;
	add.s32 	%r261, %r260, 2123724318;
	xor.b32  	%r262, %r259, %r261;
	add.s32 	%r263, %r262, 1;
	shl.b32 	%r264, %r263, 4;
	add.s32 	%r265, %r264, -1556008596;
	add.s32 	%r266, %r262, 1013904243;
	xor.b32  	%r267, %r265, %r266;
	shr.u32 	%r268, %r263, 5;
	add.s32 	%r269, %r268, -939442524;
	xor.b32  	%r270, %r267, %r269;
	add.s32 	%r271, %r270, %r255;
	shl.b32 	%r272, %r271, 4;
	add.s32 	%r273, %r272, -1383041155;
	add.s32 	%r274, %r271, 1013904242;
	xor.b32  	%r275, %r273, %r274;
	shr.u32 	%r276, %r271, 5;
	add.s32 	%r277, %r276, 2123724318;
	xor.b32  	%r278, %r275, %r277;
	add.s32 	%r279, %r278, %r263;
	shl.b32 	%r280, %r279, 4;
	add.s32 	%r281, %r280, -1556008596;
	add.s32 	%r282, %r279, -626627285;
	xor.b32  	%r283, %r281, %r282;
	shr.u32 	%r284, %r279, 5;
	add.s32 	%r285, %r284, -939442524;
	xor.b32  	%r286, %r283, %r285;
	add.s32 	%r287, %r286, %r271;
	shl.b32 	%r288, %r287, 4;
	add.s32 	%r289, %r288, -1383041155;
	add.s32 	%r290, %r287, -626627285;
	xor.b32  	%r291, %r289, %r290;
	shr.u32 	%r292, %r287, 5;
	add.s32 	%r293, %r292, 2123724318;
	xor.b32  	%r294, %r291, %r293;
	add.s32 	%r295, %r294, %r279;
	shl.b32 	%r296, %r295, 4;
	add.s32 	%r297, %r296, -1556008596;
	add.s32 	%r298, %r295, 2027808484;
	xor.b32  	%r299, %r297, %r298;
	shr.u32 	%r300, %r295, 5;
	add.s32 	%r301, %r300, -939442524;
	xor.b32  	%r302, %r299, %r301;
	add.s32 	%r303, %r302, %r287;
	shl.b32 	%r304, %r303, 4;
	add.s32 	%r305, %r304, -1383041155;
	add.s32 	%r306, %r303, 2027808484;
	xor.b32  	%r307, %r305, %r306;
	shr.u32 	%r308, %r303, 5;
	add.s32 	%r309, %r308, 2123724318;
	xor.b32  	%r310, %r307, %r309;
	add.s32 	%r311, %r310, %r295;
	shl.b32 	%r312, %r311, 4;
	add.s32 	%r313, %r312, -1556008596;
	add.s32 	%r314, %r311, 387276957;
	xor.b32  	%r315, %r313, %r314;
	shr.u32 	%r316, %r311, 5;
	add.s32 	%r317, %r316, -939442524;
	xor.b32  	%r318, %r315, %r317;
	add.s32 	%r319, %r318, %r303;
	shl.b32 	%r320, %r319, 4;
	add.s32 	%r321, %r320, -1383041155;
	add.s32 	%r322, %r319, 387276957;
	xor.b32  	%r323, %r321, %r322;
	shr.u32 	%r324, %r319, 5;
	add.s32 	%r325, %r324, 2123724318;
	xor.b32  	%r326, %r323, %r325;
	add.s32 	%r327, %r326, %r311;
	shl.b32 	%r328, %r327, 4;
	add.s32 	%r329, %r328, -1556008596;
	add.s32 	%r330, %r327, -1253254570;
	xor.b32  	%r331, %r329, %r330;
	shr.u32 	%r332, %r327, 5;
	add.s32 	%r333, %r332, -939442524;
	xor.b32  	%r334, %r331, %r333;
	add.s32 	%r335, %r334, %r319;
	shl.b32 	%r336, %r335, 4;
	add.s32 	%r337, %r336, -1383041155;
	add.s32 	%r338, %r335, -1253254570;
	xor.b32  	%r339, %r337, %r338;
	shr.u32 	%r340, %r335, 5;
	add.s32 	%r341, %r340, 2123724318;
	xor.b32  	%r342, %r339, %r341;
	add.s32 	%r343, %r342, %r327;
	shl.b32 	%r344, %r343, 4;
	add.s32 	%r345, %r344, -1556008596;
	add.s32 	%r346, %r343, 1401181199;
	xor.b32  	%r347, %r345, %r346;
	shr.u32 	%r348, %r343, 5;
	add.s32 	%r349, %r348, -939442524;
	xor.b32  	%r350, %r347, %r349;
	add.s32 	%r351, %r350, %r335;
	shl.b32 	%r352, %r351, 4;
	add.s32 	%r353, %r352, -1383041155;
	add.s32 	%r354, %r351, 1401181199;
	xor.b32  	%r355, %r353, %r354;
	shr.u32 	%r356, %r351, 5;
	add.s32 	%r357, %r356, 2123724318;
	xor.b32  	%r358, %r355, %r357;
	add.s32 	%r359, %r358, %r343;
	shl.b32 	%r360, %r359, 4;
	add.s32 	%r361, %r360, -1556008596;
	add.s32 	%r362, %r359, -239350328;
	xor.b32  	%r363, %r361, %r362;
	shr.u32 	%r364, %r359, 5;
	add.s32 	%r365, %r364, -939442524;
	xor.b32  	%r366, %r363, %r365;
	add.s32 	%r367, %r366, %r351;
	shl.b32 	%r368, %r367, 4;
	add.s32 	%r369, %r368, -1383041155;
	add.s32 	%r370, %r367, -239350328;
	xor.b32  	%r371, %r369, %r370;
	shr.u32 	%r372, %r367, 5;
	add.s32 	%r373, %r372, 2123724318;
	xor.b32  	%r374, %r371, %r373;
	add.s32 	%r375, %r374, %r359;
	shl.b32 	%r376, %r375, 4;
	add.s32 	%r377, %r376, -1556008596;
	add.s32 	%r378, %r375, -1879881855;
	xor.b32  	%r379, %r377, %r378;
	shr.u32 	%r380, %r375, 5;
	add.s32 	%r381, %r380, -939442524;
	xor.b32  	%r382, %r379, %r381;
	add.s32 	%r383, %r382, %r367;
	shl.b32 	%r384, %r383, 4;
	add.s32 	%r385, %r384, -1383041155;
	add.s32 	%r386, %r383, -1879881855;
	xor.b32  	%r387, %r385, %r386;
	shr.u32 	%r388, %r383, 5;
	add.s32 	%r389, %r388, 2123724318;
	xor.b32  	%r390, %r387, %r389;
	add.s32 	%r391, %r390, %r375;
	shl.b32 	%r392, %r391, 4;
	add.s32 	%r393, %r392, -1556008596;
	add.s32 	%r394, %r391, 774553914;
	xor.b32  	%r395, %r393, %r394;
	shr.u32 	%r396, %r391, 5;
	add.s32 	%r397, %r396, -939442524;
	xor.b32  	%r398, %r395, %r397;
	add.s32 	%r399, %r398, %r383;
	shl.b32 	%r400, %r399, 4;
	add.s32 	%r401, %r400, -1383041155;
	add.s32 	%r402, %r399, 774553914;
	xor.b32  	%r403, %r401, %r402;
	shr.u32 	%r404, %r399, 5;
	add.s32 	%r405, %r404, 2123724318;
	xor.b32  	%r406, %r403, %r405;
	add.s32 	%r407, %r406, %r391;
	shl.b32 	%r408, %r407, 4;
	add.s32 	%r409, %r408, -1556008596;
	add.s32 	%r410, %r407, -865977613;
	xor.b32  	%r411, %r409, %r410;
	shr.u32 	%r412, %r407, 5;
	add.s32 	%r413, %r412, -939442524;
	xor.b32  	%r414, %r411, %r413;
	add.s32 	%r415, %r414, %r399;
	shl.b32 	%r416, %r415, 4;
	add.s32 	%r417, %r416, -1383041155;
	add.s32 	%r418, %r415, -865977613;
	xor.b32  	%r419, %r417, %r418;
	shr.u32 	%r420, %r415, 5;
	add.s32 	%r421, %r420, 2123724318;
	xor.b32  	%r422, %r419, %r421;
	add.s32 	%r423, %r422, %r407;
	shl.b32 	%r424, %r423, 4;
	add.s32 	%r425, %r424, -1556008596;
	add.s32 	%r426, %r423, 1788458156;
	xor.b32  	%r427, %r425, %r426;
	shr.u32 	%r428, %r423, 5;
	add.s32 	%r429, %r428, -939442524;
	xor.b32  	%r430, %r427, %r429;
	add.s32 	%r431, %r430, %r415;
	shl.b32 	%r432, %r431, 4;
	add.s32 	%r433, %r432, -1383041155;
	add.s32 	%r434, %r431, 1788458156;
	xor.b32  	%r435, %r433, %r434;
	shr.u32 	%r436, %r431, 5;
	add.s32 	%r437, %r436, 2123724318;
	xor.b32  	%r438, %r435, %r437;
	add.s32 	%r439, %r438, %r423;
	shl.b32 	%r440, %r439, 4;
	add.s32 	%r441, %r440, -1556008596;
	add.s32 	%r442, %r439, 147926629;
	xor.b32  	%r443, %r441, %r442;
	shr.u32 	%r444, %r439, 5;
	add.s32 	%r445, %r444, -939442524;
	xor.b32  	%r446, %r443, %r445;
	add.s32 	%r447, %r446, %r431;
	shl.b32 	%r448, %r447, 4;
	add.s32 	%r449, %r448, -1383041155;
	add.s32 	%r450, %r447, 147926629;
	xor.b32  	%r451, %r449, %r450;
	shr.u32 	%r452, %r447, 5;
	add.s32 	%r453, %r452, 2123724318;
	xor.b32  	%r454, %r451, %r453;
	add.s32 	%r455, %r454, %r439;
	shl.b32 	%r456, %r455, 4;
	add.s32 	%r457, %r456, -1556008596;
	add.s32 	%r458, %r455, -1492604898;
	xor.b32  	%r459, %r457, %r458;
	shr.u32 	%r460, %r455, 5;
	add.s32 	%r461, %r460, -939442524;
	xor.b32  	%r462, %r459, %r461;
	add.s32 	%r463, %r462, %r447;
	shl.b32 	%r464, %r463, 4;
	add.s32 	%r465, %r464, -1383041155;
	add.s32 	%r466, %r463, -1492604898;
	xor.b32  	%r467, %r465, %r466;
	shr.u32 	%r468, %r463, 5;
	add.s32 	%r469, %r468, 2123724318;
	xor.b32  	%r470, %r467, %r469;
	add.s32 	%r471, %r470, %r455;
	shl.b32 	%r472, %r471, 4;
	add.s32 	%r473, %r472, -1556008596;
	add.s32 	%r474, %r471, 1161830871;
	xor.b32  	%r475, %r473, %r474;
	shr.u32 	%r476, %r471, 5;
	add.s32 	%r477, %r476, -939442524;
	xor.b32  	%r478, %r475, %r477;
	add.s32 	%r479, %r478, %r463;
	shl.b32 	%r480, %r479, 4;
	add.s32 	%r481, %r480, -1383041155;
	add.s32 	%r482, %r479, 1161830871;
	xor.b32  	%r483, %r481, %r482;
	shr.u32 	%r484, %r479, 5;
	add.s32 	%r485, %r484, 2123724318;
	xor.b32  	%r486, %r483, %r485;
	add.s32 	%r487, %r486, %r471;
	shl.b32 	%r488, %r487, 4;
	add.s32 	%r489, %r488, -1556008596;
	add.s32 	%r490, %r487, -478700656;
	xor.b32  	%r491, %r489, %r490;
	shr.u32 	%r492, %r487, 5;
	add.s32 	%r493, %r492, -939442524;
	xor.b32  	%r494, %r491, %r493;
	add.s32 	%r495, %r494, %r479;
	mad.lo.s32 	%r496, %r254, 1664525, 7271263;
	and.b32  	%r497, %r496, 16777215;
	cvt.rn.f32.u32	%f21, %r497;
	mov.f32 	%f22, 0f4B800000;
	div.approx.ftz.f32 	%f23, %f21, %f22;
	mad.lo.s32 	%r498, %r495, 1664525, 7271263;
	and.b32  	%r499, %r498, 16777215;
	cvt.rn.f32.u32	%f24, %r499;
	div.approx.ftz.f32 	%f25, %f24, %f22;
	fma.rn.ftz.f32 	%f26, %f19, %f23, %f15;
	fma.rn.ftz.f32 	%f27, %f20, %f25, %f16;
	ld.global.v2.f32 	{%f28, %f29}, [eye];
	ld.global.f32 	%f3, [eye+8];
	mov.u64 	%rd9, U;
	ldu.global.f32 	%f30, [U];
	mul.ftz.f32 	%f31, %f30, %f26;
	add.s64 	%rd10, %rd9, 4;
	ldu.global.f32 	%f32, [%rd10];
	mul.ftz.f32 	%f33, %f26, %f32;
	add.s64 	%rd11, %rd9, 8;
	ldu.global.f32 	%f34, [%rd11];
	mul.ftz.f32 	%f35, %f26, %f34;
	ldu.global.f32 	%f36, [fov];
	mov.u64 	%rd12, V;
	ldu.global.f32 	%f37, [V];
	mul.ftz.f32 	%f38, %f27, %f37;
	add.s64 	%rd13, %rd12, 4;
	ldu.global.f32 	%f39, [%rd13];
	mul.ftz.f32 	%f40, %f27, %f39;
	add.s64 	%rd14, %rd12, 8;
	ldu.global.f32 	%f41, [%rd14];
	mul.ftz.f32 	%f42, %f27, %f41;
	mul.ftz.f32 	%f43, %f38, %f36;
	mul.ftz.f32 	%f44, %f40, %f36;
	mul.ftz.f32 	%f45, %f42, %f36;
	fma.rn.ftz.f32 	%f46, %f31, %f36, %f43;
	fma.rn.ftz.f32 	%f47, %f33, %f36, %f44;
	fma.rn.ftz.f32 	%f48, %f35, %f36, %f45;
	mov.u64 	%rd15, W;
	ldu.global.f32 	%f49, [W];
	add.ftz.f32 	%f50, %f49, %f46;
	add.s64 	%rd16, %rd15, 4;
	ldu.global.f32 	%f51, [%rd16];
	add.ftz.f32 	%f52, %f47, %f51;
	add.s64 	%rd17, %rd15, 8;
	ldu.global.f32 	%f53, [%rd17];
	add.ftz.f32 	%f54, %f48, %f53;
	mul.ftz.f32 	%f55, %f52, %f52;
	fma.rn.ftz.f32 	%f56, %f50, %f50, %f55;
	fma.rn.ftz.f32 	%f57, %f54, %f54, %f56;
	sqrt.approx.ftz.f32 	%f58, %f57;
	rcp.approx.ftz.f32 	%f59, %f58;
	mul.ftz.f32 	%f4, %f50, %f59;
	mul.ftz.f32 	%f5, %f52, %f59;
	mul.ftz.f32 	%f6, %f54, %f59;
	ldu.global.u32 	%r2, [Phong];
	mov.f32 	%f60, 0f3F800000;
	st.local.v4.f32 	[%rd8], {%f60, %f60, %f60, %f60};
	mov.u32 	%r500, 0;
	st.local.u32 	[%rd8+16], %r500;
	ldu.global.u32 	%r1, [top_object];
	mov.f32 	%f7, 0f3089705F;
	mov.f32 	%f8, 0f6C4ECB8F;
	mov.u32 	%r3, 32;
	// inline asm
	call _rt_trace_64, (%r1, %f28, %f29, %f3, %f4, %f5, %f6, %r2, %f7, %f8, %rd1, %r3);
	// inline asm
	ld.local.v4.f32 	{%f61, %f62, %f63, %f64}, [%rd8];
	ld.global.u32 	%rd4, [launch_index];
	ld.global.u32 	%rd5, [launch_index+4];
	mov.u64 	%rd18, output0;
	cvta.global.u64 	%rd3, %rd18;
	mov.u32 	%r4, 2;
	mov.u32 	%r5, 16;
	mov.u64 	%rd7, 0;
	// inline asm
	call (%rd2), _rt_buffer_get_64, (%rd3, %r4, %r5, %rd4, %rd5, %rd7, %rd7);
	// inline asm
	add.ftz.f32 	%f69, %f64, 0f00000000;
	add.ftz.f32 	%f70, %f63, 0f00000000;
	add.ftz.f32 	%f71, %f62, 0f00000000;
	add.ftz.f32 	%f72, %f61, 0f00000000;
	st.v4.f32 	[%rd2], {%f72, %f71, %f70, %f69};
	ret;
}

	// .globl	_Z14any_hit_shadowv
.visible .entry _Z14any_hit_shadowv(

)
{
	.reg .f32 	%f<2>;


	mov.f32 	%f1, 0f00000000;
	st.global.v4.f32 	[prd_shadow], {%f1, %f1, %f1, %f1};
	// inline asm
	call _rt_terminate_ray, ();
	// inline asm
	ret;
}

	// .globl	_Z15keepGoingShadowv
.visible .entry _Z15keepGoingShadowv(

)
{
	.reg .pred 	%p<9>;
	.reg .f32 	%f<58>;
	.reg .b32 	%r<42>;
	.reg .f64 	%fd<103>;
	.reg .b64 	%rd<3>;


	mov.u64 	%rd1, shading_normal;
	ldu.global.v2.f32 	{%f17, %f18}, [shading_normal];
	add.s64 	%rd2, %rd1, 8;
	ldu.global.f32 	%f15, [%rd2];
	mov.u32 	%r14, 7937;
	mov.f32 	%f16, 0f00000000;
	// inline asm
	call (%f9, %f10, %f11, %f12), _rt_transform_tuple, (%r14, %f17, %f18, %f15, %f16);
	// inline asm
	mul.ftz.f32 	%f19, %f10, %f10;
	fma.rn.ftz.f32 	%f20, %f9, %f9, %f19;
	fma.rn.ftz.f32 	%f21, %f11, %f11, %f20;
	sqrt.approx.ftz.f32 	%f22, %f21;
	rcp.approx.ftz.f32 	%f23, %f22;
	mul.ftz.f32 	%f1, %f9, %f23;
	mul.ftz.f32 	%f2, %f10, %f23;
	mul.ftz.f32 	%f3, %f11, %f23;
	ld.global.f32 	%f4, [prd_shadow+16];
	setp.eq.ftz.f32	%p1, %f4, 0f00000000;
	@%p1 bra 	BB5_13;
	bra.uni 	BB5_1;

BB5_13:
	ld.global.f32 	%f37, [ray+12];
	ld.global.f32 	%f38, [ray+16];
	mul.ftz.f32 	%f39, %f2, %f38;
	fma.rn.ftz.f32 	%f40, %f1, %f37, %f39;
	ld.global.f32 	%f41, [ray+20];
	fma.rn.ftz.f32 	%f42, %f3, %f41, %f40;
	abs.ftz.f32 	%f43, %f42;
	sqrt.approx.ftz.f32 	%f57, %f43;
	ld.global.f32 	%f44, [t_hit];
	st.global.f32 	[prd_shadow+16], %f44;
	bra.uni 	BB5_14;

BB5_1:
	mov.f64 	%fd11, 0d3FEAE147AE147AE1;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r38}, %fd11;
	}
	setp.lt.s32	%p2, %r38, 2146435072;
	@%p2 bra 	BB5_4;
	bra.uni 	BB5_2;

BB5_4:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r39, %temp}, %fd11;
	}
	mov.u32 	%r40, -1023;
	setp.gt.s32	%p4, %r38, 1048575;
	@%p4 bra 	BB5_6;

	mov.f64 	%fd17, 0d434AE147AE147AE1;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r38}, %fd17;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r39, %temp}, %fd17;
	}
	mov.u32 	%r40, -1077;

BB5_6:
	shr.u32 	%r17, %r38, 20;
	add.s32 	%r41, %r40, %r17;
	and.b32  	%r18, %r38, -2146435073;
	or.b32  	%r19, %r18, 1072693248;
	mov.b64 	%fd100, {%r39, %r19};
	setp.lt.s32	%p5, %r19, 1073127583;
	@%p5 bra 	BB5_8;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r20, %temp}, %fd100;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r21}, %fd100;
	}
	add.s32 	%r22, %r21, -1048576;
	mov.b64 	%fd100, {%r20, %r22};
	add.s32 	%r41, %r41, 1;

BB5_8:
	add.f64 	%fd19, %fd100, 0d3FF0000000000000;
	// inline asm
	rcp.approx.ftz.f64 %fd18,%fd19;
	// inline asm
	neg.f64 	%fd20, %fd19;
	mov.f64 	%fd21, 0d3FF0000000000000;
	fma.rn.f64 	%fd22, %fd20, %fd18, %fd21;
	fma.rn.f64 	%fd23, %fd22, %fd22, %fd22;
	fma.rn.f64 	%fd24, %fd23, %fd18, %fd18;
	add.f64 	%fd25, %fd100, 0dBFF0000000000000;
	mul.f64 	%fd26, %fd25, %fd24;
	fma.rn.f64 	%fd27, %fd25, %fd24, %fd26;
	mul.f64 	%fd28, %fd27, %fd27;
	mov.f64 	%fd29, 0d3ED0EE258B7A8B04;
	mov.f64 	%fd30, 0d3EB1380B3AE80F1E;
	fma.rn.f64 	%fd31, %fd30, %fd28, %fd29;
	mov.f64 	%fd32, 0d3EF3B2669F02676F;
	fma.rn.f64 	%fd33, %fd31, %fd28, %fd32;
	mov.f64 	%fd34, 0d3F1745CBA9AB0956;
	fma.rn.f64 	%fd35, %fd33, %fd28, %fd34;
	mov.f64 	%fd36, 0d3F3C71C72D1B5154;
	fma.rn.f64 	%fd37, %fd35, %fd28, %fd36;
	mov.f64 	%fd38, 0d3F624924923BE72D;
	fma.rn.f64 	%fd39, %fd37, %fd28, %fd38;
	mov.f64 	%fd40, 0d3F8999999999A3C4;
	fma.rn.f64 	%fd41, %fd39, %fd28, %fd40;
	mov.f64 	%fd42, 0d3FB5555555555554;
	fma.rn.f64 	%fd43, %fd41, %fd28, %fd42;
	sub.f64 	%fd44, %fd25, %fd27;
	add.f64 	%fd45, %fd44, %fd44;
	neg.f64 	%fd46, %fd27;
	fma.rn.f64 	%fd47, %fd46, %fd25, %fd45;
	mul.f64 	%fd48, %fd24, %fd47;
	mul.f64 	%fd49, %fd28, %fd43;
	fma.rn.f64 	%fd50, %fd49, %fd27, %fd48;
	xor.b32  	%r23, %r41, -2147483648;
	mov.u32 	%r24, 1127219200;
	mov.b64 	%fd51, {%r23, %r24};
	mov.u32 	%r25, -2147483648;
	mov.b64 	%fd52, {%r25, %r24};
	sub.f64 	%fd53, %fd51, %fd52;
	mov.f64 	%fd54, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd55, %fd53, %fd54, %fd27;
	neg.f64 	%fd56, %fd53;
	fma.rn.f64 	%fd57, %fd56, %fd54, %fd55;
	sub.f64 	%fd58, %fd57, %fd27;
	sub.f64 	%fd59, %fd50, %fd58;
	mov.f64 	%fd60, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd61, %fd53, %fd60, %fd59;
	add.f64 	%fd101, %fd55, %fd61;
	bra.uni 	BB5_9;

BB5_2:
	abs.f64 	%fd14, %fd11;
	setp.gtu.f64	%p3, %fd14, 0d7FF0000000000000;
	mov.f64 	%fd101, 0d3FFAE147AE147AE1;
	@%p3 bra 	BB5_9;

	mov.f64 	%fd101, 0dFFF8000000000000;

BB5_9:
	ld.global.f32 	%f24, [t_hit];
	sub.ftz.f32 	%f25, %f24, %f4;
	abs.ftz.f32 	%f26, %f25;
	cvt.ftz.f64.f32	%fd62, %f26;
	mul.f64 	%fd6, %fd101, %fd62;
	mov.f64 	%fd63, 0d3FF71547652B82FE;
	mul.rn.f64 	%fd64, %fd6, %fd63;
	mov.f64 	%fd65, 0d4338000000000000;
	add.rn.f64 	%fd66, %fd64, %fd65;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r11, %temp}, %fd66;
	}
	mov.f64 	%fd67, 0dC338000000000000;
	add.rn.f64 	%fd68, %fd66, %fd67;
	mov.f64 	%fd69, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd70, %fd68, %fd69, %fd6;
	mov.f64 	%fd71, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd72, %fd68, %fd71, %fd70;
	mov.f64 	%fd73, 0d3E928AF3FCA213EA;
	mov.f64 	%fd74, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd75, %fd74, %fd72, %fd73;
	mov.f64 	%fd76, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd77, %fd75, %fd72, %fd76;
	mov.f64 	%fd78, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd79, %fd77, %fd72, %fd78;
	mov.f64 	%fd80, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd81, %fd79, %fd72, %fd80;
	mov.f64 	%fd82, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd83, %fd81, %fd72, %fd82;
	mov.f64 	%fd84, 0d3F81111111122322;
	fma.rn.f64 	%fd85, %fd83, %fd72, %fd84;
	mov.f64 	%fd86, 0d3FA55555555502A1;
	fma.rn.f64 	%fd87, %fd85, %fd72, %fd86;
	mov.f64 	%fd88, 0d3FC5555555555511;
	fma.rn.f64 	%fd89, %fd87, %fd72, %fd88;
	mov.f64 	%fd90, 0d3FE000000000000B;
	fma.rn.f64 	%fd91, %fd89, %fd72, %fd90;
	mov.f64 	%fd92, 0d3FF0000000000000;
	fma.rn.f64 	%fd93, %fd91, %fd72, %fd92;
	fma.rn.f64 	%fd94, %fd93, %fd72, %fd92;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r12, %temp}, %fd94;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r13}, %fd94;
	}
	shl.b32 	%r26, %r11, 20;
	add.s32 	%r27, %r13, %r26;
	mov.b64 	%fd102, {%r12, %r27};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r28}, %fd6;
	}
	mov.b32 	 %f27, %r28;
	abs.ftz.f32 	%f5, %f27;
	setp.lt.ftz.f32	%p6, %f5, 0f4086232B;
	@%p6 bra 	BB5_12;

	setp.lt.f64	%p7, %fd6, 0d0000000000000000;
	add.f64 	%fd95, %fd6, 0d7FF0000000000000;
	selp.f64	%fd102, 0d0000000000000000, %fd95, %p7;
	setp.geu.ftz.f32	%p8, %f5, 0f40874800;
	@%p8 bra 	BB5_12;

	shr.u32 	%r29, %r11, 31;
	add.s32 	%r30, %r11, %r29;
	shr.s32 	%r31, %r30, 1;
	shl.b32 	%r32, %r31, 20;
	add.s32 	%r33, %r32, %r13;
	mov.b64 	%fd96, {%r12, %r33};
	sub.s32 	%r34, %r11, %r31;
	shl.b32 	%r35, %r34, 20;
	add.s32 	%r36, %r35, 1072693248;
	mov.u32 	%r37, 0;
	mov.b64 	%fd97, {%r37, %r36};
	mul.f64 	%fd102, %fd96, %fd97;

BB5_12:
	mul.f64 	%fd98, %fd102, %fd102;
	mul.f64 	%fd99, %fd98, %fd98;
	cvt.rn.ftz.f32.f64	%f28, %fd99;
	ld.global.f32 	%f29, [ray+12];
	ld.global.f32 	%f30, [ray+16];
	mul.ftz.f32 	%f31, %f2, %f30;
	fma.rn.ftz.f32 	%f32, %f1, %f29, %f31;
	ld.global.f32 	%f33, [ray+20];
	fma.rn.ftz.f32 	%f34, %f3, %f33, %f32;
	abs.ftz.f32 	%f35, %f34;
	sqrt.approx.ftz.f32 	%f36, %f35;
	mul.ftz.f32 	%f57, %f28, %f36;

BB5_14:
	ld.global.v4.f32 	{%f45, %f46, %f47, %f48}, [prd_shadow];
	mul.ftz.f32 	%f50, %f57, %f48;
	mul.ftz.f32 	%f52, %f57, %f47;
	mul.ftz.f32 	%f54, %f57, %f46;
	mul.ftz.f32 	%f56, %f57, %f45;
	st.global.v4.f32 	[prd_shadow], {%f56, %f54, %f52, %f50};
	// inline asm
	call _rt_ignore_intersection, ();
	// inline asm
	ret;
}

	// .globl	_Z9keepGoingv
.visible .entry _Z9keepGoingv(

)
{
	.reg .f32 	%f<13>;


	ldu.global.v4.f32 	{%f1, %f2, %f3, %f4}, [prdr];
	mul.ftz.f32 	%f6, %f4, 0f3F666666;
	mul.ftz.f32 	%f8, %f3, 0f3F666666;
	mul.ftz.f32 	%f10, %f2, 0f3F666666;
	mul.ftz.f32 	%f12, %f1, 0f3F666666;
	st.global.v4.f32 	[prdr], {%f12, %f10, %f8, %f6};
	// inline asm
	call _rt_ignore_intersection, ();
	// inline asm
	ret;
}

	// .globl	_Z5shadev
.visible .entry _Z5shadev(

)
{
	.local .align 16 .b8 	__local_depot7[32];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<3>;
	.reg .f32 	%f<101>;
	.reg .b32 	%r<6>;
	.reg .f64 	%fd<13>;
	.reg .b64 	%rd<8>;


	mov.u64 	%rd7, __local_depot7;
	cvta.local.u64 	%SP, %rd7;
	add.u64 	%rd2, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd2;
	mov.f32 	%f25, 0f3F800000;
	st.local.v4.f32 	[%rd1], {%f25, %f25, %f25, %f25};
	ldu.global.v4.f32 	{%f26, %f27, %f28, %f29}, [lightDir];
	neg.ftz.f32 	%f1, %f26;
	neg.ftz.f32 	%f2, %f27;
	neg.ftz.f32 	%f3, %f28;
	mov.u64 	%rd3, shading_normal;
	ldu.global.v2.f32 	{%f33, %f34}, [shading_normal];
	add.s64 	%rd4, %rd3, 8;
	ldu.global.f32 	%f23, [%rd4];
	mov.u32 	%r1, 7937;
	mov.f32 	%f24, 0f00000000;
	// inline asm
	call (%f17, %f18, %f19, %f20), _rt_transform_tuple, (%r1, %f33, %f34, %f23, %f24);
	// inline asm
	mul.ftz.f32 	%f35, %f18, %f18;
	fma.rn.ftz.f32 	%f36, %f17, %f17, %f35;
	fma.rn.ftz.f32 	%f37, %f19, %f19, %f36;
	sqrt.approx.ftz.f32 	%f38, %f37;
	rcp.approx.ftz.f32 	%f39, %f38;
	mul.ftz.f32 	%f40, %f17, %f39;
	mul.ftz.f32 	%f41, %f18, %f39;
	mul.ftz.f32 	%f42, %f19, %f39;
	mul.ftz.f32 	%f43, %f40, %f1;
	mul.ftz.f32 	%f44, %f41, %f27;
	sub.ftz.f32 	%f45, %f43, %f44;
	mul.ftz.f32 	%f46, %f42, %f28;
	sub.ftz.f32 	%f47, %f45, %f46;
	max.ftz.f32 	%f4, %f24, %f47;
	setp.leu.ftz.f32	%p1, %f4, 0f00000000;
	@%p1 bra 	BB7_2;

	ld.global.f32 	%f56, [t_hit];
	ld.global.f32 	%f57, [ray+12];
	ld.global.f32 	%f58, [ray+16];
	ld.global.f32 	%f59, [ray+20];
	ld.global.f32 	%f60, [ray];
	fma.rn.ftz.f32 	%f48, %f56, %f57, %f60;
	ld.global.f32 	%f61, [ray+4];
	fma.rn.ftz.f32 	%f49, %f56, %f58, %f61;
	ld.global.f32 	%f62, [ray+8];
	fma.rn.ftz.f32 	%f50, %f56, %f59, %f62;
	ld.global.u32 	%r3, [Shadow];
	ld.global.u32 	%r2, [top_object];
	mov.f32 	%f54, 0f3A83126F;
	mov.f32 	%f55, 0f6C4ECB8F;
	mov.u32 	%r4, 32;
	// inline asm
	call _rt_trace_64, (%r2, %f48, %f49, %f50, %f1, %f2, %f3, %r3, %f54, %f55, %rd2, %r4);
	// inline asm

BB7_2:
	ld.local.v4.f32 	{%f63, %f64, %f65, %f66}, [%rd1];
	mul.ftz.f32 	%f5, %f4, %f63;
	mul.ftz.f32 	%f6, %f4, %f64;
	mul.ftz.f32 	%f7, %f4, %f65;
	ld.global.v4.f32 	{%f70, %f71, %f72, %f73}, [diffuse];
	mul.ftz.f32 	%f98, %f70, 0f3FA66666;
	mul.ftz.f32 	%f99, %f71, 0f3FA66666;
	mul.ftz.f32 	%f100, %f72, 0f3FA66666;
	ld.global.u32 	%r5, [texCount];
	setp.lt.s32	%p2, %r5, 1;
	@%p2 bra 	BB7_4;

	ld.global.v2.f32 	{%f77, %f78}, [texCoord];
	tex.2d.v4.f32.f32	{%f81, %f82, %f83, %f84}, [tex0, {%f77, %f78}];
	mul.ftz.f32 	%f98, %f98, %f81;
	mul.ftz.f32 	%f99, %f99, %f82;
	mul.ftz.f32 	%f100, %f100, %f83;

BB7_4:
	cvt.ftz.f64.f32	%fd1, %f5;
	add.f64 	%fd2, %fd1, 0d3FD3333333333333;
	cvt.ftz.f64.f32	%fd3, %f98;
	mul.f64 	%fd4, %fd2, %fd3;
	cvt.rn.ftz.f32.f64	%f85, %fd4;
	cvt.ftz.f64.f32	%fd5, %f6;
	add.f64 	%fd6, %fd5, 0d3FD3333333333333;
	cvt.ftz.f64.f32	%fd7, %f99;
	mul.f64 	%fd8, %fd6, %fd7;
	cvt.rn.ftz.f32.f64	%f86, %fd8;
	cvt.ftz.f64.f32	%fd9, %f7;
	add.f64 	%fd10, %fd9, 0d3FD3333333333333;
	cvt.ftz.f64.f32	%fd11, %f100;
	mul.f64 	%fd12, %fd10, %fd11;
	cvt.rn.ftz.f32.f64	%f87, %fd12;
	ld.global.v4.f32 	{%f88, %f89, %f90, %f91}, [prdr];
	mul.ftz.f32 	%f93, %f89, %f86;
	mul.ftz.f32 	%f95, %f88, %f85;
	st.global.v2.f32 	[prdr], {%f95, %f93};
	mul.ftz.f32 	%f97, %f90, %f87;
	st.global.f32 	[prdr+8], %f97;
	ret;
}

	// .globl	_Z15shadePointLightv
.visible .entry _Z15shadePointLightv(

)
{
	.local .align 16 .b8 	__local_depot8[32];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<3>;
	.reg .f32 	%f<110>;
	.reg .b32 	%r<7>;
	.reg .f64 	%fd<15>;
	.reg .b64 	%rd<8>;


	mov.u64 	%rd7, __local_depot8;
	cvta.local.u64 	%SP, %rd7;
	add.u64 	%rd2, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd2;
	mov.f32 	%f29, 0f3F800000;
	st.local.v4.f32 	[%rd1], {%f29, %f29, %f29, %f29};
	mov.u32 	%r2, 0;
	st.local.u32 	[%rd1+16], %r2;
	mov.u64 	%rd3, shading_normal;
	ldu.global.v2.f32 	{%f30, %f31}, [shading_normal];
	add.s64 	%rd4, %rd3, 8;
	ldu.global.f32 	%f27, [%rd4];
	mov.u32 	%r1, 7937;
	mov.f32 	%f28, 0f00000000;
	// inline asm
	call (%f21, %f22, %f23, %f24), _rt_transform_tuple, (%r1, %f30, %f31, %f27, %f28);
	// inline asm
	mul.ftz.f32 	%f32, %f22, %f22;
	fma.rn.ftz.f32 	%f33, %f21, %f21, %f32;
	fma.rn.ftz.f32 	%f34, %f23, %f23, %f33;
	sqrt.approx.ftz.f32 	%f35, %f34;
	rcp.approx.ftz.f32 	%f36, %f35;
	mul.ftz.f32 	%f37, %f21, %f36;
	mul.ftz.f32 	%f38, %f22, %f36;
	mul.ftz.f32 	%f39, %f23, %f36;
	ld.global.f32 	%f40, [ray+12];
	ld.global.f32 	%f41, [t_hit];
	ld.global.f32 	%f42, [ray+16];
	ld.global.f32 	%f43, [ray+20];
	ld.global.f32 	%f44, [ray];
	fma.rn.ftz.f32 	%f1, %f41, %f40, %f44;
	ld.global.f32 	%f45, [ray+4];
	fma.rn.ftz.f32 	%f2, %f41, %f42, %f45;
	ld.global.f32 	%f46, [ray+8];
	fma.rn.ftz.f32 	%f3, %f41, %f43, %f46;
	ld.global.v4.f32 	{%f47, %f48, %f49, %f50}, [lightPos];
	sub.ftz.f32 	%f52, %f47, %f1;
	sub.ftz.f32 	%f54, %f48, %f2;
	sub.ftz.f32 	%f56, %f49, %f3;
	mul.ftz.f32 	%f57, %f54, %f54;
	fma.rn.ftz.f32 	%f58, %f52, %f52, %f57;
	fma.rn.ftz.f32 	%f59, %f56, %f56, %f58;
	sqrt.approx.ftz.f32 	%f4, %f59;
	rcp.approx.ftz.f32 	%f60, %f4;
	mul.ftz.f32 	%f5, %f52, %f60;
	mul.ftz.f32 	%f6, %f54, %f60;
	mul.ftz.f32 	%f7, %f56, %f60;
	mul.ftz.f32 	%f61, %f38, %f6;
	fma.rn.ftz.f32 	%f62, %f37, %f5, %f61;
	fma.rn.ftz.f32 	%f63, %f39, %f7, %f62;
	max.ftz.f32 	%f8, %f28, %f63;
	setp.leu.ftz.f32	%p1, %f8, 0f00000000;
	@%p1 bra 	BB8_2;

	ld.global.u32 	%r4, [Shadow];
	cvt.ftz.f64.f32	%fd1, %f4;
	add.f64 	%fd2, %fd1, 0d3F847AE147AE147B;
	cvt.rn.ftz.f32.f64	%f71, %fd2;
	ld.global.u32 	%r3, [top_object];
	mov.f32 	%f70, 0f360637BD;
	mov.u32 	%r5, 32;
	// inline asm
	call _rt_trace_64, (%r3, %f1, %f2, %f3, %f5, %f6, %f7, %r4, %f70, %f71, %rd2, %r5);
	// inline asm

BB8_2:
	ld.local.v4.f32 	{%f72, %f73, %f74, %f75}, [%rd1];
	mul.ftz.f32 	%f9, %f8, %f72;
	mul.ftz.f32 	%f10, %f8, %f73;
	mul.ftz.f32 	%f11, %f8, %f74;
	ld.global.v4.f32 	{%f79, %f80, %f81, %f82}, [diffuse];
	mul.ftz.f32 	%f107, %f79, 0f3FA66666;
	mul.ftz.f32 	%f108, %f80, 0f3FA66666;
	mul.ftz.f32 	%f109, %f81, 0f3FA66666;
	ld.global.u32 	%r6, [texCount];
	setp.lt.s32	%p2, %r6, 1;
	@%p2 bra 	BB8_4;

	ld.global.v2.f32 	{%f86, %f87}, [texCoord];
	tex.2d.v4.f32.f32	{%f90, %f91, %f92, %f93}, [tex0, {%f86, %f87}];
	mul.ftz.f32 	%f107, %f107, %f90;
	mul.ftz.f32 	%f108, %f108, %f91;
	mul.ftz.f32 	%f109, %f109, %f92;

BB8_4:
	cvt.ftz.f64.f32	%fd3, %f9;
	add.f64 	%fd4, %fd3, 0d3FD3333333333333;
	cvt.ftz.f64.f32	%fd5, %f107;
	mul.f64 	%fd6, %fd4, %fd5;
	cvt.rn.ftz.f32.f64	%f94, %fd6;
	cvt.ftz.f64.f32	%fd7, %f10;
	add.f64 	%fd8, %fd7, 0d3FD3333333333333;
	cvt.ftz.f64.f32	%fd9, %f108;
	mul.f64 	%fd10, %fd8, %fd9;
	cvt.rn.ftz.f32.f64	%f95, %fd10;
	cvt.ftz.f64.f32	%fd11, %f11;
	add.f64 	%fd12, %fd11, 0d3FD3333333333333;
	cvt.ftz.f64.f32	%fd13, %f109;
	mul.f64 	%fd14, %fd12, %fd13;
	cvt.rn.ftz.f32.f64	%f96, %fd14;
	ld.global.v4.f32 	{%f97, %f98, %f99, %f100}, [prdr];
	mul.ftz.f32 	%f102, %f98, %f95;
	mul.ftz.f32 	%f104, %f97, %f94;
	st.global.v2.f32 	[prdr], {%f104, %f102};
	mul.ftz.f32 	%f106, %f99, %f96;
	st.global.f32 	[prdr+8], %f106;
	ret;
}

	// .globl	_Z10shadeLightv
.visible .entry _Z10shadeLightv(

)
{
	.reg .f32 	%f<2>;


	mov.f32 	%f1, 0f3F800000;
	st.global.v4.f32 	[prdr], {%f1, %f1, %f1, %f1};
	ret;
}

	// .globl	_Z6shadowv
.visible .entry _Z6shadowv(

)
{
	.reg .f32 	%f<2>;


	mov.f32 	%f1, 0f3DCCCCCD;
	st.global.v4.f32 	[prd_shadow], {%f1, %f1, %f1, %f1};
	// inline asm
	call _rt_terminate_ray, ();
	// inline asm
	ret;
}

	// .globl	_Z9exceptionv
.visible .entry _Z9exceptionv(

)
{
	.reg .f32 	%f<3>;
	.reg .b32 	%r<3>;
	.reg .b64 	%rd<8>;


	ld.global.u32 	%rd3, [launch_index];
	ld.global.u32 	%rd4, [launch_index+4];
	mov.u64 	%rd7, output0;
	cvta.global.u64 	%rd2, %rd7;
	mov.u32 	%r1, 2;
	mov.u32 	%r2, 16;
	mov.u64 	%rd6, 0;
	// inline asm
	call (%rd1), _rt_buffer_get_64, (%rd2, %r1, %r2, %rd3, %rd4, %rd6, %rd6);
	// inline asm
	mov.f32 	%f1, 0f00000000;
	mov.f32 	%f2, 0f3F800000;
	st.v4.f32 	[%rd1], {%f2, %f1, %f1, %f2};
	ret;
}

	// .globl	_Z4missv
.visible .entry _Z4missv(

)
{
	.reg .f32 	%f<2>;


	mov.f32 	%f1, 0f00000000;
	st.global.v4.f32 	[prdr], {%f1, %f1, %f1, %f1};
	ret;
}

	// .globl	_Z10missShadowv
.visible .entry _Z10missShadowv(

)
{
	.reg .f32 	%f<2>;


	mov.f32 	%f1, 0f3F800000;
	st.global.v4.f32 	[prdr], {%f1, %f1, %f1, %f1};
	ret;
}

	// .globl	_Z10alpha_testv
.visible .entry _Z10alpha_testv(

)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<9>;
	.reg .b64 	%rd<2>;


	ldu.global.v2.f32 	{%f1, %f2}, [texCoord];
	tex.2d.v4.f32.f32	{%f5, %f6, %f7, %f8}, [tex0, {%f1, %f2}];
	setp.geu.ftz.f32	%p1, %f8, 0f3E800000;
	@%p1 bra 	BB14_2;

	// inline asm
	call _rt_ignore_intersection, ();
	// inline asm

BB14_2:
	ret;
}

	// .globl	_Z17alpha_test_shadowv
.visible .entry _Z17alpha_test_shadowv(

)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<10>;
	.reg .b64 	%rd<2>;


	ldu.global.v2.f32 	{%f1, %f2}, [texCoord];
	tex.2d.v4.f32.f32	{%f5, %f6, %f7, %f8}, [tex0, {%f1, %f2}];
	setp.lt.ftz.f32	%p1, %f8, 0f3E800000;
	@%p1 bra 	BB15_2;
	bra.uni 	BB15_1;

BB15_2:
	// inline asm
	call _rt_ignore_intersection, ();
	// inline asm
	bra.uni 	BB15_3;

BB15_1:
	mov.f32 	%f9, 0f00000000;
	st.global.v4.f32 	[prd_shadow], {%f9, %f9, %f9, %f9};
	// inline asm
	call _rt_terminate_ray, ();
	// inline asm

BB15_3:
	ret;
}

	// .globl	_Z20geometryintersectioni
.visible .entry _Z20geometryintersectioni(
	.param .u32 _Z20geometryintersectioni_param_0
)
{
	.reg .pred 	%p<11>;
	.reg .f32 	%f<154>;
	.reg .b32 	%r<44>;
	.reg .b64 	%rd<117>;


	ld.param.u32 	%r13, [_Z20geometryintersectioni_param_0];
	mul.lo.s32 	%r14, %r13, 3;
	cvt.s64.s32	%rd6, %r14;
	mov.u64 	%rd40, index_buffer;
	cvta.global.u64 	%rd5, %rd40;
	mov.u32 	%r11, 1;
	mov.u32 	%r10, 4;
	mov.u64 	%rd39, 0;
	// inline asm
	call (%rd4), _rt_buffer_get_64, (%rd5, %r11, %r10, %rd6, %rd39, %rd39, %rd39);
	// inline asm
	ld.u32 	%rd12, [%rd4];
	mov.u64 	%rd41, vertex_buffer;
	cvta.global.u64 	%rd11, %rd41;
	mov.u32 	%r12, 16;
	// inline asm
	call (%rd10), _rt_buffer_get_64, (%rd11, %r11, %r12, %rd12, %rd39, %rd39, %rd39);
	// inline asm
	ld.v4.f32 	{%f7, %f8, %f9, %f10}, [%rd10];
	add.s32 	%r15, %r14, 1;
	cvt.s64.s32	%rd18, %r15;
	// inline asm
	call (%rd16), _rt_buffer_get_64, (%rd5, %r11, %r10, %rd18, %rd39, %rd39, %rd39);
	// inline asm
	ld.u32 	%rd24, [%rd16];
	// inline asm
	call (%rd22), _rt_buffer_get_64, (%rd11, %r11, %r12, %rd24, %rd39, %rd39, %rd39);
	// inline asm
	ld.v4.f32 	{%f14, %f15, %f16, %f17}, [%rd22];
	add.s32 	%r16, %r14, 2;
	cvt.s64.s32	%rd30, %r16;
	// inline asm
	call (%rd28), _rt_buffer_get_64, (%rd5, %r11, %r10, %rd30, %rd39, %rd39, %rd39);
	// inline asm
	ld.u32 	%rd36, [%rd28];
	// inline asm
	call (%rd34), _rt_buffer_get_64, (%rd11, %r11, %r12, %rd36, %rd39, %rd39, %rd39);
	// inline asm
	sub.ftz.f32 	%f21, %f14, %f7;
	sub.ftz.f32 	%f22, %f15, %f8;
	sub.ftz.f32 	%f23, %f16, %f9;
	ld.v4.f32 	{%f24, %f25, %f26, %f27}, [%rd34];
	sub.ftz.f32 	%f31, %f7, %f24;
	sub.ftz.f32 	%f32, %f8, %f25;
	sub.ftz.f32 	%f33, %f9, %f26;
	mul.ftz.f32 	%f34, %f23, %f32;
	mul.ftz.f32 	%f35, %f22, %f33;
	sub.ftz.f32 	%f1, %f34, %f35;
	mul.ftz.f32 	%f36, %f21, %f33;
	mul.ftz.f32 	%f37, %f23, %f31;
	sub.ftz.f32 	%f2, %f36, %f37;
	mul.ftz.f32 	%f38, %f22, %f31;
	mul.ftz.f32 	%f39, %f21, %f32;
	sub.ftz.f32 	%f3, %f38, %f39;
	ld.global.f32 	%f40, [ray+12];
	ld.global.f32 	%f41, [ray+16];
	mul.ftz.f32 	%f42, %f41, %f2;
	fma.rn.ftz.f32 	%f43, %f40, %f1, %f42;
	ld.global.f32 	%f44, [ray+20];
	fma.rn.ftz.f32 	%f45, %f44, %f3, %f43;
	rcp.approx.ftz.f32 	%f46, %f45;
	ld.global.f32 	%f47, [ray];
	sub.ftz.f32 	%f48, %f7, %f47;
	ld.global.f32 	%f49, [ray+4];
	sub.ftz.f32 	%f50, %f8, %f49;
	ld.global.f32 	%f51, [ray+8];
	sub.ftz.f32 	%f52, %f9, %f51;
	mul.ftz.f32 	%f53, %f46, %f48;
	mul.ftz.f32 	%f54, %f46, %f50;
	mul.ftz.f32 	%f55, %f46, %f52;
	mul.ftz.f32 	%f56, %f41, %f55;
	mul.ftz.f32 	%f57, %f54, %f44;
	sub.ftz.f32 	%f58, %f56, %f57;
	mul.ftz.f32 	%f59, %f53, %f44;
	mul.ftz.f32 	%f60, %f55, %f40;
	sub.ftz.f32 	%f61, %f59, %f60;
	mul.ftz.f32 	%f62, %f54, %f40;
	mul.ftz.f32 	%f63, %f53, %f41;
	sub.ftz.f32 	%f64, %f62, %f63;
	mul.ftz.f32 	%f65, %f32, %f61;
	fma.rn.ftz.f32 	%f66, %f31, %f58, %f65;
	fma.rn.ftz.f32 	%f4, %f33, %f64, %f66;
	mul.ftz.f32 	%f67, %f22, %f61;
	fma.rn.ftz.f32 	%f68, %f21, %f58, %f67;
	fma.rn.ftz.f32 	%f5, %f23, %f64, %f68;
	mul.ftz.f32 	%f69, %f2, %f54;
	fma.rn.ftz.f32 	%f70, %f1, %f53, %f69;
	fma.rn.ftz.f32 	%f6, %f3, %f55, %f70;
	ld.global.f32 	%f71, [ray+32];
	setp.lt.ftz.f32	%p1, %f6, %f71;
	ld.global.f32 	%f72, [ray+28];
	setp.gt.ftz.f32	%p2, %f6, %f72;
	and.pred  	%p3, %p1, %p2;
	setp.ge.ftz.f32	%p4, %f4, 0f00000000;
	and.pred  	%p5, %p3, %p4;
	setp.ge.ftz.f32	%p6, %f5, 0f00000000;
	and.pred  	%p7, %p5, %p6;
	add.ftz.f32 	%f73, %f4, %f5;
	setp.le.ftz.f32	%p8, %f73, 0f3F800000;
	and.pred  	%p9, %p7, %p8;
	@!%p9 bra 	BB16_3;
	bra.uni 	BB16_1;

BB16_1:
	// inline asm
	call (%r17), _rt_potential_intersection, (%f6);
	// inline asm
	setp.eq.s32	%p10, %r17, 0;
	@%p10 bra 	BB16_3;

	// inline asm
	call (%rd42), _rt_buffer_get_64, (%rd5, %r11, %r10, %rd6, %rd39, %rd39, %rd39);
	// inline asm
	ld.u32 	%rd50, [%rd42];
	mov.u64 	%rd115, normal;
	cvta.global.u64 	%rd49, %rd115;
	// inline asm
	call (%rd48), _rt_buffer_get_64, (%rd49, %r11, %r12, %rd50, %rd39, %rd39, %rd39);
	// inline asm
	ld.v4.f32 	{%f75, %f76, %f77, %f78}, [%rd48];
	// inline asm
	call (%rd54), _rt_buffer_get_64, (%rd5, %r11, %r10, %rd18, %rd39, %rd39, %rd39);
	// inline asm
	ld.u32 	%rd62, [%rd54];
	// inline asm
	call (%rd60), _rt_buffer_get_64, (%rd49, %r11, %r12, %rd62, %rd39, %rd39, %rd39);
	// inline asm
	ld.v4.f32 	{%f82, %f83, %f84, %f85}, [%rd60];
	// inline asm
	call (%rd66), _rt_buffer_get_64, (%rd5, %r11, %r10, %rd30, %rd39, %rd39, %rd39);
	// inline asm
	ld.u32 	%rd74, [%rd66];
	// inline asm
	call (%rd72), _rt_buffer_get_64, (%rd49, %r11, %r12, %rd74, %rd39, %rd39, %rd39);
	// inline asm
	ld.v4.f32 	{%f89, %f90, %f91, %f92}, [%rd72];
	// inline asm
	call (%rd78), _rt_buffer_get_64, (%rd5, %r11, %r10, %rd6, %rd39, %rd39, %rd39);
	// inline asm
	ld.u32 	%rd86, [%rd78];
	mov.u64 	%rd116, texCoord0;
	cvta.global.u64 	%rd85, %rd116;
	// inline asm
	call (%rd84), _rt_buffer_get_64, (%rd85, %r11, %r12, %rd86, %rd39, %rd39, %rd39);
	// inline asm
	ld.v4.f32 	{%f96, %f97, %f98, %f99}, [%rd84];
	// inline asm
	call (%rd90), _rt_buffer_get_64, (%rd5, %r11, %r10, %rd18, %rd39, %rd39, %rd39);
	// inline asm
	ld.u32 	%rd98, [%rd90];
	// inline asm
	call (%rd96), _rt_buffer_get_64, (%rd85, %r11, %r12, %rd98, %rd39, %rd39, %rd39);
	// inline asm
	ld.v4.f32 	{%f103, %f104, %f105, %f106}, [%rd96];
	// inline asm
	call (%rd102), _rt_buffer_get_64, (%rd5, %r11, %r10, %rd30, %rd39, %rd39, %rd39);
	// inline asm
	ld.u32 	%rd110, [%rd102];
	// inline asm
	call (%rd108), _rt_buffer_get_64, (%rd85, %r11, %r12, %rd110, %rd39, %rd39, %rd39);
	// inline asm
	ld.v4.f32 	{%f110, %f111, %f112, %f113}, [%rd108];
	mov.f32 	%f117, 0f3F800000;
	sub.ftz.f32 	%f118, %f117, %f4;
	sub.ftz.f32 	%f119, %f118, %f5;
	mul.ftz.f32 	%f120, %f4, %f82;
	mul.ftz.f32 	%f121, %f4, %f83;
	mul.ftz.f32 	%f122, %f4, %f84;
	fma.rn.ftz.f32 	%f123, %f119, %f75, %f120;
	fma.rn.ftz.f32 	%f124, %f119, %f76, %f121;
	fma.rn.ftz.f32 	%f125, %f119, %f77, %f122;
	fma.rn.ftz.f32 	%f126, %f5, %f89, %f123;
	fma.rn.ftz.f32 	%f127, %f5, %f90, %f124;
	fma.rn.ftz.f32 	%f128, %f5, %f91, %f125;
	mul.ftz.f32 	%f129, %f127, %f127;
	fma.rn.ftz.f32 	%f130, %f126, %f126, %f129;
	fma.rn.ftz.f32 	%f131, %f128, %f128, %f130;
	sqrt.approx.ftz.f32 	%f132, %f131;
	rcp.approx.ftz.f32 	%f133, %f132;
	mul.ftz.f32 	%f134, %f128, %f133;
	mul.ftz.f32 	%f135, %f127, %f133;
	mul.ftz.f32 	%f136, %f126, %f133;
	st.global.v2.f32 	[shading_normal], {%f136, %f135};
	st.global.f32 	[shading_normal+8], %f134;
	mul.ftz.f32 	%f137, %f4, %f103;
	mul.ftz.f32 	%f138, %f4, %f104;
	mul.ftz.f32 	%f139, %f4, %f105;
	fma.rn.ftz.f32 	%f140, %f119, %f96, %f137;
	fma.rn.ftz.f32 	%f141, %f119, %f97, %f138;
	fma.rn.ftz.f32 	%f142, %f119, %f98, %f139;
	fma.rn.ftz.f32 	%f143, %f5, %f112, %f142;
	fma.rn.ftz.f32 	%f144, %f5, %f111, %f141;
	fma.rn.ftz.f32 	%f145, %f5, %f110, %f140;
	st.global.v2.f32 	[texCoord], {%f145, %f144};
	st.global.f32 	[texCoord+8], %f143;
	mul.ftz.f32 	%f146, %f2, %f2;
	fma.rn.ftz.f32 	%f147, %f1, %f1, %f146;
	fma.rn.ftz.f32 	%f148, %f3, %f3, %f147;
	sqrt.approx.ftz.f32 	%f149, %f148;
	rcp.approx.ftz.f32 	%f150, %f149;
	mul.ftz.f32 	%f151, %f3, %f150;
	mul.ftz.f32 	%f152, %f2, %f150;
	mul.ftz.f32 	%f153, %f1, %f150;
	st.global.v2.f32 	[geometric_normal], {%f153, %f152};
	st.global.f32 	[geometric_normal+8], %f151;
	mov.u32 	%r43, 0;
	// inline asm
	call (%r42), _rt_report_intersection, (%r43);
	// inline asm

BB16_3:
	ret;
}

	// .globl	_Z11boundingboxiPf
.visible .entry _Z11boundingboxiPf(
	.param .u32 _Z11boundingboxiPf_param_0,
	.param .u64 _Z11boundingboxiPf_param_1
)
{
	.reg .pred 	%p<6>;
	.reg .f32 	%f<54>;
	.reg .b32 	%r<19>;
	.reg .b64 	%rd<42>;


	ld.param.u32 	%r13, [_Z11boundingboxiPf_param_0];
	ld.param.u64 	%rd3, [_Z11boundingboxiPf_param_1];
	mul.lo.s32 	%r14, %r13, 3;
	cvt.s64.s32	%rd6, %r14;
	mov.u64 	%rd40, index_buffer;
	cvta.global.u64 	%rd5, %rd40;
	mov.u32 	%r11, 1;
	mov.u32 	%r10, 4;
	mov.u64 	%rd39, 0;
	// inline asm
	call (%rd4), _rt_buffer_get_64, (%rd5, %r11, %r10, %rd6, %rd39, %rd39, %rd39);
	// inline asm
	ld.u32 	%rd12, [%rd4];
	mov.u64 	%rd41, vertex_buffer;
	cvta.global.u64 	%rd11, %rd41;
	mov.u32 	%r12, 16;
	// inline asm
	call (%rd10), _rt_buffer_get_64, (%rd11, %r11, %r12, %rd12, %rd39, %rd39, %rd39);
	// inline asm
	ld.v4.f32 	{%f11, %f12, %f13, %f14}, [%rd10];
	add.s32 	%r15, %r14, 1;
	cvt.s64.s32	%rd18, %r15;
	// inline asm
	call (%rd16), _rt_buffer_get_64, (%rd5, %r11, %r10, %rd18, %rd39, %rd39, %rd39);
	// inline asm
	ld.u32 	%rd24, [%rd16];
	// inline asm
	call (%rd22), _rt_buffer_get_64, (%rd11, %r11, %r12, %rd24, %rd39, %rd39, %rd39);
	// inline asm
	ld.v4.f32 	{%f15, %f16, %f17, %f18}, [%rd22];
	add.s32 	%r16, %r14, 2;
	cvt.s64.s32	%rd30, %r16;
	// inline asm
	call (%rd28), _rt_buffer_get_64, (%rd5, %r11, %r10, %rd30, %rd39, %rd39, %rd39);
	// inline asm
	ld.u32 	%rd36, [%rd28];
	// inline asm
	call (%rd34), _rt_buffer_get_64, (%rd11, %r11, %r12, %rd36, %rd39, %rd39, %rd39);
	// inline asm
	sub.ftz.f32 	%f19, %f15, %f11;
	sub.ftz.f32 	%f20, %f16, %f12;
	sub.ftz.f32 	%f21, %f17, %f13;
	ld.v4.f32 	{%f22, %f23, %f24, %f25}, [%rd34];
	sub.ftz.f32 	%f26, %f22, %f11;
	sub.ftz.f32 	%f27, %f23, %f12;
	sub.ftz.f32 	%f28, %f24, %f13;
	mul.ftz.f32 	%f29, %f20, %f28;
	mul.ftz.f32 	%f30, %f21, %f27;
	sub.ftz.f32 	%f31, %f29, %f30;
	mul.ftz.f32 	%f32, %f21, %f26;
	mul.ftz.f32 	%f33, %f19, %f28;
	sub.ftz.f32 	%f34, %f32, %f33;
	mul.ftz.f32 	%f35, %f19, %f27;
	mul.ftz.f32 	%f36, %f20, %f26;
	sub.ftz.f32 	%f37, %f35, %f36;
	mul.ftz.f32 	%f38, %f34, %f34;
	fma.rn.ftz.f32 	%f39, %f31, %f31, %f38;
	fma.rn.ftz.f32 	%f40, %f37, %f37, %f39;
	sqrt.approx.ftz.f32 	%f10, %f40;
	mov.pred 	%p5, 0;
	setp.leu.ftz.f32	%p4, %f10, 0f00000000;
	@%p4 bra 	BB17_2;

	abs.ftz.f32 	%f41, %f10;
	setp.neu.ftz.f32	%p5, %f41, 0f7F800000;

BB17_2:
	cvta.to.global.u64 	%rd2, %rd3;
	@%p5 bra 	BB17_4;
	bra.uni 	BB17_3;

BB17_4:
	min.ftz.f32 	%f42, %f11, %f15;
	min.ftz.f32 	%f43, %f42, %f22;
	min.ftz.f32 	%f44, %f12, %f16;
	min.ftz.f32 	%f45, %f44, %f23;
	min.ftz.f32 	%f46, %f13, %f17;
	min.ftz.f32 	%f47, %f46, %f24;
	st.global.f32 	[%rd2], %f43;
	st.global.f32 	[%rd2+4], %f45;
	st.global.f32 	[%rd2+8], %f47;
	max.ftz.f32 	%f48, %f11, %f15;
	max.ftz.f32 	%f49, %f48, %f22;
	max.ftz.f32 	%f50, %f12, %f16;
	max.ftz.f32 	%f51, %f50, %f23;
	max.ftz.f32 	%f52, %f13, %f17;
	max.ftz.f32 	%f53, %f52, %f24;
	st.global.f32 	[%rd2+12], %f49;
	st.global.f32 	[%rd2+16], %f51;
	st.global.f32 	[%rd2+20], %f53;
	bra.uni 	BB17_5;

BB17_3:
	mov.u32 	%r17, 2096152002;
	st.global.u32 	[%rd2+8], %r17;
	st.global.u32 	[%rd2+4], %r17;
	st.global.u32 	[%rd2], %r17;
	mov.u32 	%r18, -51331646;
	st.global.u32 	[%rd2+20], %r18;
	st.global.u32 	[%rd2+16], %r18;
	st.global.u32 	[%rd2+12], %r18;

BB17_5:
	ret;
}


